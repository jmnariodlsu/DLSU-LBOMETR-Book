[["index.html", "LBOMETR Course Book 1 Introduction 1.1 About Me", " LBOMETR Course Book Jem Marie M. Nario 2026-01-24 1 Introduction Welcome to the LBOMETR Course Book! This book is designed to guide students through the course by providing all necessary resources, materials, and instructions. LBOMETR This course book is intended to ensure that DLSU Carlos L. Tiu-School of Economics students will be able to learn more about Econometrics using R. You will find sections on the syllabus, course assessments, and group projects, as well as guidance for navigating the course effectively. 1.1 About Me My name is Jem Marie M. Nario, and I am your lecturer for this course. I am excited to guide you through this journey of learning and discovery since I am also on a journey of learning and discovery while teaching part-time. This book is a trial version whnb ich will be updated along the course as it also serves as a practice for me. Email: jem.nario@dlsu.edu.ph LinkedIn: linkedin.com/in/jmnario/ Feel free to reach out with any questions or concerns throughout the course. "],["syllabus.html", "2 Syllabus 2.1 General Course Description 2.2 Specific Course Description 2.3 Final Course Outputs 2.4 Generative AI-Use Policy 2.5 Classroom Policies", " 2 Syllabus 2.1 General Course Description This course introduces Economics majors to more advanced commands and techniques used in econometric software package R commonly used in empirical research. 2.2 Specific Course Description This course familiarizes Economics majors with advanced techniques in R for empirical research. Students will also gather and analyze their own real-world data to investigate a specific economic problem, applying econometric methods and presenting their findings in a final project. 2.3 Final Course Outputs CLOs Output Due Date CLO 1,2,4 Data Storytelling (OR) Week 10 CLO 1-4 Data Story Archive (PF/PR) 18:00 Tuesday Week 14 CLO 1-3 Problem Sets (QA) 18:00 Weeks 6 and 12 CLO 1,3 Short Quizzes (QA) Weeks 2-6, 8, 11-12 CLO 4 Class Participation (TW/OB) Weeks 1-12 2.4 Generative AI-Use Policy For each component of the final grade defined above, students must identify the generative AI usage policy level. The levels are: Free to Use – AI may be used without restriction. Allowed in Specific Contexts – AI may be used only for clearly defined purposes and must be cited. Banned – AI use is strictly prohibited. Grade Component Usage Policy Level Notes Data Storytelling (OR) Allowed in Specific Contexts Students may use generative AI only to brainstorm ideas, create outlines, and design slides. AI must not be used to generate or check final code or analysis. Data Story Archive (PF/PR) Banned AI use is strictly prohibited for writing, coding, or analyzing the archive. Work must reflect independent technical skill. Problem Sets (QA) Banned Students must independently write and debug code; AI may not generate or check solutions. Short Quizzes (QA) Banned AI use is not allowed during quizzes. Class Participation (TW/OB) Banned All participation must be based on students’ own understanding and contributions. This course is an applied coding and econometrics laboratory, designed to develop students’ ability to analyze real-world data, write reproducible code, and interpret econometric results independently. To support student learning and promote the responsible use of emerging technologies, students may use generative AI tools (e.g., ChatGPT, Gemini, etc.) only for conceptual or exploratory coding assistance, such as: ● Understanding function syntax or usage ● Exploring coding strategies ● Learning general debugging approaches The use of generative AI is strictly prohibited for the following: ● Generating or checking final code for the Data Story Archive (report and code) ● Generating or checking code for Problem Sets ● Short quizzes ● Any submission intended to reflect independent technical skill Overreliance on AI may hinder students’ understanding of key concepts, which are essential to success in this course. Any unauthorized use of AI will be treated as academic dishonesty, in accordance with the university’s academic integrity policy. Students are encouraged to consult the instructor if they are unsure about the appropriate use of AI for specific tasks. 2.5 Classroom Policies 1. Assessments All major assessments are described below. Deadlines, formats, and submission requirements are non-negotiable. Assessment Format &amp; Submission Notes Short Quizzes In-class, 2 coding questions per session. Students work with a buddy to check each other’s answers. Each student underlines economic theory and econometric reasoning in their buddy’s paper and places check marks for each. No quizzes on Weeks 6,7, 8, 9, 10, 12, 13, 14. Problem Set 1 Group submission (hard copy). Handwritten discussion + typed step-by-step R code + printed/pasted graphs. Covers material up to descriptive statistics. Due Week 6. Questions are provided on Day 1 in the LBOMETR Course Book. Problem Set 2 Group submission (hard copy). Handwritten discussion + typed step-by-step R code + printed/pasted graphs. Covers material from descriptive statistics to formal tests of assumptions. Due Week 12. Questions are provided on Day 1 in the LBOMETR Course Book. Data Storytelling (Oral Presentation) Group presentation in HyFlex classroom. Must include R visualizations and clear explanation of methodology, results, and conclusions. Graded individually, based on contribution, clarity, and engagement. Data Story Archive Group submission (hard copy) compiling R scripts, analyses, visualizations, and interpretations. Demonstrates independent mastery; must be concise, reproducible, and complete. AI or outside generation is not allowed. Hard copy must be submitted by Week 14. 2. Groupings Students will be divided into 5 groups of 6 on the first day of class. Groups are assigned based on in-class skill surveys: comfort with R and economic theory. Groups remain fixed throughout the semester. Roles (e.g., introduction, data cleaning, analysis, visualization, discussion) may rotate within the group for fairness, except for the assigned monitor if used. 3. Appointments &amp; Consultations Data Story Topic Consultation: Groups must meet with the professor before Week 5. Topic, methodology, or scope changes after Week 6 without notice will incur a 50% deduction on the Data Story grade. Mock Presentation &amp; Archive Consultation: Groups are encouraged to schedule 15-minute in-person sessions after Mock Presentation submission to improve the Data Story Archive. Slots are booked via a provided link. Other Consultations: Can be done via email. Lecturer responds only between 8 AM – 6 PM. 4. Grading Notes Perfect scores (100%) are very rare. Excellent students typically achieve up to ~95%. Grades reflect demonstrated mastery, quality of outputs, and adherence to rubrics. Attendance, participation, buddy system compliance, and group contributions are part of the class participation grade. No general incentives or extra credit are provided. 5. Class Monitor Responsibilities One student monitor per session, rotating weekly or biweekly, will oversee the buddy system. Responsibilities: Collect all buddy-checked papers after class. Record for each student: Buddy’s name who checked the paper. Number of checks received (0, 1, or 2). Ensure all buddy system procedures are followed (underlines and check marks). Submit a tally sheet to the professor by 6 PM of class day. Important: The monitor does not grade anything. Failure to follow these steps may affect participation points for the monitor or the class. 6. Attendance Attendance is monitored during in-person sessions. Attendance points contribute to class participation. Unexcused absence will not be able to have full marks in class participation and might miss short quizzes. Excused absence: no deduction (documentation required). 7. Buddy System Students must complete buddy checks for short quizzes as described in Section 1. Compliance is verified by the class monitor and reflected in participation scores. 8. Problem Sets Students are expected to complete and submit the assigned problem sets on time, including discussion, code, and visualizations as described above. 9. Data Storytelling &amp; Data Story Archive Follow all guidelines for oral presentations and written archive submissions, including hard copy submission and proper documentation of R code. Consultations are highly recommended to refine presentations and archive outputs. 10. Use of Course Materials All learning and teaching materials provided in this class are for the exclusive use of students enrolled in this course, Term 2, AY2025-26. Students are not allowed to upload, share, or distribute these materials publicly or to anyone other than their groupmates/classmates without the instructor’s permission. 2.5.1 EXCUSED ABSENCES POLICY: Students must process requests for excused absences from their respective Associate Deans. For SOE students, the Associate Dean of the School of Economics will only process requests for excused absences due to medical and mental health reasons. Covid-related leave requests are no longer accepted as of August 30, 2023. Students must provide official documentation from the Office of Student Affairs (OSA) for absences related to official university functions.  Procedure: Timing: Submit requests immediately upon returning to campus and no later than seven working days from the return date.  Request Letter: Write a letter to the Associate Dean including: ○ Course details (course name, section, faculty names, and emails) ○ Dates of absence(s) ○ Reason for absence with relevant details Supporting Documents: Attach validated documents from the appropriate university offices. Submission: Combine the letter and supporting documents into a single PDF and upload viathis form. Approved absences will be communicated to you and your professors within three working days. Note that processing is done only during regular weekday office hours.  Important: Only complete requests will be processed. Falsifying records is a major offense as per the Student Handbook (Section 9, pp. 85-87). Note: The syllabus is unique to the course per Term, per AY. Final syllabus uploaded in Animospace. "],["course-assessments.html", "3 Course Assessments 3.1 Short Quizzes 3.2 Problem Sets (1 and 2) 3.3 Data Storytelling 3.4 Data Story Archive 3.5 Participation 3.6 Grading System 3.7 Grading Scale", " 3 Course Assessments 3.1 Short Quizzes Format: In-class, handwritten, two questions per session. Questions involve: Coding: Write R code to solve the problem. Discussion: Explain your solution in terms of: Economic theory behind the answer. Econometric reasoning (why variables/methods were chosen). Visuals can be shown to your buddy, who will check your work. Buddy System: Each student pairs with a seatmate to verify the discussion: Underline economic theory and econometric reasoning in peer’s paper. Place a check for each component found. Class Monitor Responsibilities One student monitor per session, rotating weekly or biweekly, will oversee the buddy system. Responsibilities: Collect all buddy-checked papers after class. Record for each student: Buddy’s name who checked the paper. Number of checks received (0, 1, or 2). Ensure all buddy system procedures are followed (underlines and check marks). Submit a tally sheet to the professor by 6 PM of class day. Important: The monitor does not grade anything. Failure to follow these steps may affect participation points for the monitor or the class. Expectations: Both checks must be present to receive full participation credit. No shortcuts; discussion must reflect understanding. 3.2 Problem Sets (1 and 2) Topic Assignment and Scope Topics and scope for Problem Sets 1 and 2 will be assigned randomly on the first day of class. Assignment will be done by drawing from prepared topic papers. Assigned topics are final and will be finalized by Week 2. Students may not change, narrow, or expand their assigned scope without instructor approval. If two groups converge on substantively similar topics or datasets, both submissions will be penalized. Format: Hard copy submission only, with handwritten discussion. R code can be typed and printed for submission. Graphics must be printed and pasted into the submission. Guidelines: Problem Sets 1 &amp; 2 questions are provided in the LBOMETR Course Book on the first day of class. Each problem must include: Discussion: Handwritten explanation of the solution. R Script: Step-by-step, well-commented, reproducible code. Graphics: Printed plots, properly labeled. Submission deadlines: PS1: Week 6 (covers material until Descriptive Statistics). PS2: Week 12 (covers material from Descriptive Statistics to Formal Tests of Assumptions). Expectations: Students must demonstrate understanding of economic theory and econometric reasoning in discussion. The same groupings apply in all group-related outputs. Only essential outputs should be included; do not submit unnecessary or repetitive results. Problem Set Rubric (Group Graded) Criteria Exemplary (90–100) Satisfactory (78–89) Developing (72–77) Beginning (&lt;72) Weight Data Cleaning &amp; Preparation Data is fully imported, cleaned, and transformed. Missing values, inconsistencies, and errors are handled effectively. Decisions are logical and appropriate for messy datasets. Mostly clean; minor errors or inconsistencies remain. Basic understanding of cleaning demonstrated. Partially cleaned; several errors remain. Some steps missing or unclear. Data largely unclean or incorrectly processed. Minimal understanding of preparation. 25 Coding &amp; Step-by-Step Process Code is correct, reproducible, well-organized, and clearly commented. Workflow is logical and easy to follow. Mostly correct; minor errors or inefficiencies. Workflow mostly clear. Code partially correct or poorly organized. Workflow unclear or incomplete. Code largely incorrect, not reproducible, or disorganized. Workflow missing. 30 Analysis &amp; Interpretation (Discussion) Answers are complete, insightful, and clearly interpret results in context. Discussion shows critical thinking. Answers mostly correct; interpretation present but limited. Some insights missing. Answers partially correct; interpretation weak or incomplete. Answers incorrect or missing; interpretation absent. 25 Graphics &amp; Visualization Visuals are clear, professional, and effectively support the discussion. Correctly printed and pasted. Visuals mostly clear and relevant; minor issues. Basic or unclear visuals; limited relevance. Missing, incorrect, or irrelevant visuals. 10 Presentation &amp; Documentation Submission is neat, organized, and easy to follow. Typed code separated from handwritten discussion. All required components included. Submission mostly organized; minor issues in clarity or order. Submission somewhat disorganized; some components missing or hard to follow. Submission poorly organized, incomplete, or difficult to follow. 10 Total 100 points (group) 3.3 Data Storytelling Format: Live in-person presentation, slides submitted electronically. Mock Presentation Slides submitted via email at 21:00 a day before the mock presentation. Final Presentation Slides submitted as a link via email at 21:00 a day before the scheduled presentation. Guidelines: Presentation duration: 10 minutes, followed by 5-minute Q&amp;A. Structure: Introduction: Topic, research question, significance Methods: Data and analysis methodology Results: Key findings using R-generated visualizations Discussion &amp; Conclusion: Implications and actionable recommendations Each group member must actively participate, meaning, speak during the presentation. No cue cards or reading from their laptops, or cellphones; presenters must be familiar with their slides. Slides must reflect economic reasoning and econometric reasoning. Room to be used will be reserved for both online and in-person audiences. Feedback will be given during the Data Storytelling and must be considered when making the Data Story Archive. Data Storytelling Rubric (Individually Graded) Criteria Exemplary Satisfactory Developing Beginning Weight Content &amp; Narrative Quality Student clearly owns a specific section. Introduction, methods, and results are clear, concise, logically presented, and analytically interpreted. Conclusions or implications are insightful and actionable. Section is clear and correct but mostly descriptive. Interpretation is present but limited. Conclusions are solid but not fully actionable. Section is vague, rushed, or weakly connected. Interpretation is superficial. Conclusions are simplistic or partially missing. Section is unclear, disorganized, or incorrect. Major parts of discussion or conclusions are missing. 40 Visualizations &amp; Analytical Support Student demonstrates clear ownership of visuals or analytical elements. Visuals are professional, polished, and strongly support the story. Any dynamic elements are used effectively. Visuals are appropriate and support the analysis, but design or relevance could be improved. Minor flaws or missed opportunities. Visuals are basic, poorly designed, or loosely connected. Some key visual aids missing. Visuals are missing, irrelevant, or poorly designed. 30 Delivery, Engagement &amp; Individual Contribution Student presents confidently, speaks naturally, and clearly explains their section. Demonstrates preparation and understanding. Contribution is observable in the presentation itself. Delivery is generally clear. Student shows understanding but occasionally relies on notes. Contribution is evident but not fully developed. Delivery is hesitant or partially scripted. Understanding of section is weak. Contribution is unclear. Delivery is minimal or absent. Student cannot demonstrate understanding of their section. 30 Total 100 points (individual) 3.4 Data Story Archive Format: Single hard copy PDF submission for the instructor. Content Requirements: Cover Page: Title, group members, submission date. Table of Contents: Clear page references. Data Story Report: Maximum 12 pages. Introduction: Problem statement and research question. Methods: Data sources, methodology, analysis techniques. Results: Key findings with R-generated visuals. Discussion &amp; Conclusion: Implications and recommendations. References: Expected to have more than 10 references; APA format Appendix: Maximum 5 pages, supporting tables or plots only. R Scripts: Maximum 10 pages, rendered from Quarto Markdown. Must include data cleaning steps, outputs, and plots. Group Reflection: Strictly 2 pages. Discuss teamwork, learning outcomes, and growth in data analysis during the whole duration of the course. Submission Instructions: Deadline: 18:00 TUESDAY OF WEEK 14 Expectations: Archive must reflect independent group work. No generative AI or external assistance in final output. Data Story Archive Rubric (Group Graded) Criteria Exemplary Satisfactory Developing Beginning Weight Content &amp; Storytelling (Report) Report is clear, concise, logically structured, and fully explains the analysis. Results are interpreted correctly, insights are highlighted, and conclusions are actionable. No irrelevant or redundant material included. Report is generally clear and correct but may be somewhat descriptive or slightly unorganized. Interpretation of results is present but not fully analytical. Report has gaps in clarity, logic, or completeness. Results are mostly descriptive. Conclusions are weak or partially missing. Report is unclear, incomplete, or disorganized. Major parts of analysis, results, or conclusions are missing or incorrect. 40 Technical Work (Code &amp; Analysis) Code is correct, fully reproducible, neat, well-commented, and logically structured. Step-by-step workflow is clear. Only relevant outputs are shown; no unnecessary tables or raw dumps. Code is mostly correct and reproducible, but minor inefficiencies, clutter, or documentation gaps exist. Some irrelevant outputs may be present. Code runs but has errors, poor structure, weak documentation, or unclear workflow. Outputs may be excessive or partly irrelevant. Code is largely incorrect, incomplete, not reproducible, or disorganized. Outputs are missing or meaningless. 45 Presentation &amp; Organization (Archive) Archive is professional, well-organized, and easy to navigate. Report and code are clearly separated. File naming and readability are consistent and logical. Archive is generally organized but may have minor inconsistencies or minor clutter. Separation of report and code is acceptable. Archive is somewhat confusing or inconsistent. Report and code separation is unclear. Archive is poorly organized, confusing, or incomplete. Report and code are difficult to access or understand. 15 Total 100 points (group) 3.5 Participation Buddy System Form: Attendance &amp; Engagement and Buddy System Participation will be monitored and checked through the Buddy System Evaluation Form. Individual Evaluation Form: Each student must also complete a Group Work Evaluation Form assessing group mates . The form must be signed to certify accuracy and truthfulness. Submission Requirements: Submit the signed evaluation forms alongside your Data Story Archive Report. Grading Notes: Attendance &amp; Engagement: Tracked via buddy form (presence in class/workshop, active participation). Buddy System Participation: Accuracy of buddy checks, initials, and verification. Group Work Contribution: Quality, quantity, and timeliness of contributions to problem sets and presentations. Collaboration &amp; Communication: Professional, constructive, and coordinated communication within the group. Participation Rubric (Individually Graded) Criteria Exemplary (90–100) Satisfactory (78–89) Developing (72–77) Beginning (&lt;72) Weight Attendance &amp; Engagement Attends all meetings/classes and actively participates in discussions, activities, and workshops. Demonstrates initiative and preparedness. Attends most meetings/classes (≥80%) and participates adequately. Minor lapses in engagement. Attends some meetings/classes (≥60%) or participates inconsistently. Minimal contribution in discussions. Frequently absent (&lt;60%) or disengaged. Rarely participates. 25% Buddy System Participation Always performs buddy responsibilities accurately: checks seatmate’s discussion, underlines components, initials verification, ensures accountability. Usually performs buddy responsibilities correctly; occasional minor lapses. Sometimes performs buddy responsibilities; inconsistencies in marking or verifying. Rarely or never performs buddy responsibilities; no accountability. 20% Group Work Contribution Actively contributes to group activities (problem sets, data storytelling). Attends meetings, shares workload equitably, helps group succeed. Participates in group activities most of the time. Completes assigned tasks with minor support needed. Limited participation in group activities. Contributes only partially to assigned tasks. Minimal or no participation in group activities. Does not contribute to group tasks. 30% Collaboration &amp; Communication Communicates effectively and professionally within the group. Supports peers, resolves conflicts constructively, and helps coordinate tasks. Communicates adequately within the group. Minor issues in coordination or collaboration. Communication within the group is inconsistent; conflicts or coordination issues sometimes occur. Poor or absent communication. Causes confusion or conflict in group. 25% Total 100 points 3.6 Grading System Data Storytelling 25% Data Story Archive 35% Problem Sets (2) 15% Short Quizzes 15% Class Participation 10% Total 100% 3.7 Grading Scale 97.00 - 100.00 4.0 90.00 – 96.99 3.5 85.00 – 89.99 3.0 80.00 – 84.99 2.5 75.00 – 79.99 2.0 70.00 – 74.99 1.5 65.00 – 69.99 1.0 00.00 – 64.99 0.0 Note: For course credit, students should get a minimum score of 65.00% (equivalent to a grade of 1.0) "],["problem-sets.html", "4 Problem Sets 4.1 Introduction 4.2 Assigned Topics List (General and Specific) 4.3 Problem Set 1 - Data Management to Descriptive Statistics and Conceptual Endogeneity 4.4 Problem Set 2 - Testable Hypotheses, OLS, Diagnostics, Robustness 4.5 Reminders:", " 4 Problem Sets 4.1 Introduction You are a team assigned to conduct research on one of the following topics. Each group will receive a specific topic randomly from the list below. Your tasks are divided into two Problem Sets: Problem Set 1: Data Management Visualization Descriptive Statistics Conceptual Endogeneity Problem Set 2 Formulate Testable Hypotheses OLS Estimation Diagnostics Sensitivity/Robustness Checks Important: All datasets must come from PSA OpenSTAT or World Bank Open Data. If you want to use other datasets, you must inform the lecturer by Week 2. No Kaggle or any cleaned datasets allowed. 4.2 Assigned Topics List (General and Specific) Trade and Economic Outcomes a. Export volume and regional economic growth b. Imports, domestic production, and household income c. Trade openness and employment in key sectors Agriculture and Productivity a. Crop yield differences by farm size b. Fertilizer input and productivity c. Regional specialization in agriculture Money, Banking and Household Finance a. Household access to banking and income b. Regional credit availability and small business activity c. Income, savings, and household financial stability Stocks and Capital Markets a. Stock market index movements and GDP b. Stock volatility and investment or savings c. Economic shocks and market performance Education and Human Capital a. Educational attainment and earnings b. Regional schooling differences and income disparities c. Education spending and enrollment/completion rates Health and Economic Outcomes a. Health expenditure and labor productivity b. Regional health access and income c. Health outcomes and employment 4.3 Problem Set 1 - Data Management to Descriptive Statistics and Conceptual Endogeneity Deadline: Week 6 Note: HW means handwritten. Data Management and Cleaning Acquire dataset(s) for your assigned topic Clean data (handle missing values, recode variables, reshape, etc.) Report observations before and after cleaning (HW) Data Visualization Create at least 3 visualizations For each visualization: Explain why you chose it (HW) Discuss what it shows in economic terms (HW) Interpret patterns, trends, or anomalies (HW) Descriptive Statistics Compute summary statistics (mean, median, SD) Compare across groups, regions, or categories Discuss findings in economic terms (HW) Conceptual Endogeneity / Confounding Variables Identify at least one variable that might confound relationships (HW) Discuss how it could bias interpretation (HW) Economic Discussion Summarize your findings clearly (HW) Link patterns to economic reasoning or policy (HW) 4.4 Problem Set 2 - Testable Hypotheses, OLS, Diagnostics, Robustness Deadline: Week 12 Note: HW means handwritten. Formulate Testable Hypotheses Clearly define dependent and independent variables OLS Estimation Run bivariate OLS Run multivariate OLS with controls Report coefficients, standard errors, and R2 (Note: This can be printed and pasted) Discuss (HW): Economic interpretation of coefficients Can the OLS be interpreted causally? Why or why not? Potential sources of bias Sensitivity/ Robustness Checks Test whether results hold with different sets of control variables Perform subsample analysis (i.e., gender, region, time period) Discuss which results are robust, which change and why (HW) Please emphasize your discussion with economic interpretation (HW) Diagnostics or Formal Tests Multicollinearity (VIF) Heteroskedasticity (BP or White) Functional form (RESET) Discuss the implications of the results (HW) Economic Discussion (HW) Compare bivariate vs multivariate results and the sensitivity checks Summarize findings with Problem Set 1, policy, limitations 4.5 Reminders: Hard copy submission is the only submission accepted. All with (HW) means these are handwritten. Please write legibly. Typed R code printed and included. Plots are printed and pasted together with the handwritten discussion. Only include essential outputs meaning, no need to print the dataset contents, whatsoever. First pages would be the answers to all questions together then, next pages would be the step-by-step process with code chunks in R. In printing the Quarto Markdown file for submission, put in the code chunks the following line on top where you see the {r}. It should be like this: {r, eval=FALSE}. This is so that the results will not appear in the HTML. You can then print the Quarto Markdown clearly. Only do this when you are printing the R codes. "],["basic-introduction-to-r.html", "5 Basic Introduction to R 5.1 Session Information 5.2 Preliminaries 5.3 Packages 5.4 Setting up the Working Directory 5.5 Cleaning the Environment (Do This Regularly) 5.6 Quarto Markdown 5.7 Working Directories and File Management 5.8 Mini-Exercise: First Quarto Render (Mandatory per Individual)", " 5 Basic Introduction to R This portion of the book offers an introduction to the basics of R. R offers a wide variety of functionality. Note that this book only offers basic Econometric analysis. It will be useful to have some basic familiarity with R and its syntax but this is not strictly necessary. Each chapter includes both R code and results to make it easier for students to follow along, even without detailed knowledge of R. 5.1 Session Information This version of the book was built using R version 4.4.2. See below for the session information: ## R version 4.5.2 (2025-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 11 x64 (build 26200) ## ## Matrix products: default ## LAPACK version 3.12.1 ## ## locale: ## [1] LC_COLLATE=English_Netherlands.utf8 LC_CTYPE=English_Netherlands.utf8 LC_MONETARY=English_Netherlands.utf8 ## [4] LC_NUMERIC=C LC_TIME=English_Netherlands.utf8 ## ## time zone: Asia/Manila ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] digest_0.6.39 R6_2.6.1 bookdown_0.46 fastmap_1.2.0 xfun_0.55 cachem_1.1.0 knitr_1.51 ## [8] htmltools_0.5.9 rmarkdown_2.30 lifecycle_1.0.4 cli_3.6.5 sass_0.4.10 jquerylib_0.1.4 compiler_4.5.2 ## [15] rstudioapi_0.17.1 tools_4.5.2 evaluate_1.0.5 bslib_0.9.0 yaml_2.3.12 jsonlite_2.0.0 rlang_1.1.6 5.2 Preliminaries The first step is to gain access to R, which is free and available on the R website: http://cran.r-project.org/. Simply go to the R website, select the appropriate location and operating system, and follow the instructions to download the base distribution of R. RStudio offers a user friendly environment to run R and is recommended. Once R is opened, we can begin to run commands. R commands can be run directly from the console, from the R script editor or from a text editor separate from R. 5.2.1 Understanding the RStudio Screen Console (Bottom Left) This is where you see the output from your code Error messages Warnings You can type R commands directly in the console after the &gt; and press Enter to run them. Try it! Type 3*9 Use the console for: Quick calculations Testing commands Seeing results Important! Anything types only in the console is not saved. Script/Editor Area (Top Left) The Script area is where you write and save your code or Quarto documents. This is where R scripts and qmd files are written. Code here is saved, reproducible, and reusable. To run code from the script: Select a line and press Ctrl+Enter (Windows) or Cmd+Enter (Mac) or just place the cursor beside the line to run it. Run a whole chunk in Quarto Rule: Always write code in the script/editor, not in the console. Environment (Top Right) The Environment shows all objects currently in memory such as data frames, variables, functions, models. Try this: type jmn&lt;-1101 in the console. After running this, jmn will appear in the Environment. If something does NOT appear, it does not exist in your session. Files, Plots, Packages, Help, Viewer (Bottom Right) This panel has multiple tabs: Files Shows files in your working directory. Your working directory can be seen just below the Console, the one after ~ Use this to navigate project files Plots Displays graphs created by code Packages Shows list of installed packages. Checkboxes allow loading/unloading packages but you still need to add in the code library() in scripts for reproducibility. Help Displays help pages Viewer Shows rendered HTML outputs Used when previewing Quarto documents R offers detailed help files for each function. To access help, run: ?sum All lines proceeded by a # are comments and will not run*. For example: # This is a comment. R will not recognize this as a command. 5.3 Packages Each package of interest must be installed and loaded before it can be used. The packages will not be immediately available when R is opened. A package only has to be installed once on a computer, but the package will have to be loaded every time R is restarted. We can install a package individually as we need them. For example, to install tidyverse and psych, we would do: install.packages(&quot;tidyverse&quot;) install.packages(&quot;psych&quot;) In the tidyverse package, the ggplot2 is usually included; if you do not see the package in the Packages list at the lower right, you can do this: if(!(&quot;ggplot2&quot; %in% installed.packages()[,&quot;Package&quot;])) install.packages(&quot;ggplot2&quot;) Now that we have our packages successfully installed, we can go ahead and load them into R. Here we will load the tidyverse package as an example. We can use of all the functions available in that package once it is loaded into R. We load packages by using a library() function. The input is the name of the package, not in quotes. library(tidyverse) We can look up all of the functions within a package by using a help() function. For example, let’s look at the functions available in the tidyverse package. help(package = tidyverse) Note that the package argument is necessary to look up all of the functions. We can also detach a package if we no longer want it loaded. This is sometimes useful if two packages do not play well together. Here we will use a detach() function. detach(package:tidyverse) For simplicity, we will assume that the reader has restarted R at the beginning of each tutorial. 5.4 Setting up the Working Directory MOST IMPORTANT! If your working directory is incorrect, R will not find your files and your code will fail even if it is correct. 5.4.1 What is a Working Directory? The working directory is the folder where R looks for data files, saves outputs, where .qmd files should be placed. You will only use one main local folder as your working directory (technically two: one in your laptop, one in your university account computer) 5.4.2 Required Folder Structure Create a folder: DLSU_COURSE_SECTION This folder is your local working directory. On university computers: create this folder inside your university account storage. On your personal computer: create this folder anywhere convenient for you. All qmd files must be placed inside this folder! 5.4.3 Setting the Working Directory in RStudio This method works on both Windows and Mac and avoids typing errors. Open RStudio Go to Session&gt;Set Working Directory&gt;Choose Working Directory Select the folder DLSU_COURSE_Section Click Open Once set, R will treat this folder as the default location for all files; meaning, all files in the course should be placed in this folder. Download files then place in this folder. 5.4.4 Setting the Working Directory Using Code This is a hassle as you will manually code working directory using setwd() Windows: # Use double backslashes \\\\ or forward slashes / setwd(&quot;C:\\\\Users\\\\YourUsername\\\\Documents\\\\DLSU_COURSE_Section&quot;) setwd(&quot;C:/Users/YourUsername/Documents/DLSU_COURSE_Section&quot;) Mac: # Use forward slashes / setwd(&quot;/Users/YourUsername/Documents/DLSU_LBOMETR_Section&quot;) How to get the path? I forgot! Just kidding. I just right-click on the file and copy as path name. I am not sure how it is with Mac, I think same, right click but press option so the path name will show up. To confirm your working directory: getwd() If the printed path is NOT DLSU_COURSE_Section, fix it. 5.5 Cleaning the Environment (Do This Regularly) You should clean your environment at the start of a new lecture, when switching datasets, or when something behaves unexpectedly. # Remove all objects from the environment rm(list = ls()) # Free up memory (makes processor faster) gc() The Environment panel should be empty. You are always starting with a clean session. 5.6 Quarto Markdown In this course, Quarto Markdown (.qmd files). Quarto Markdown is a tool for creating documents, reports and presentations using Markdown and executable code. 5.6.1 Installing Quarto in R Before starting, install the quarto R package if not already installed: install.packages(&quot;quarto&quot;) 5.6.2 Starting a Quarto Document To begin creating a Quarto document, follow these steps: Open RStudio. Go to File &gt; New File &gt; Quarto Document. Choose the document type (e.g., HTML, PDF, Word, etc.) and specify whether the document will include code. For ease, we will use the html document type. Use the visual editor for ease of editing. 5.6.3 YAML Header Use Here is the YAML header for all quarto documents that you will submit along with line-by-line explanations. title: “TITLE of the FILE” This contains the title of the document. It appears at the top and in the browser tab. author: “put your name here” Replace with your name. Identifies the document author. date: today Automatically inserts the current date. format: html: toc: true theme: united embed-resources: true Format specifies the output type (html in this case), adds a table of contents, sets a bootstrap html theme (you can use other themes but this is preferred), embeds all resources in the html file. knitr: opts_chunk: warning: false message: false Controls code chunk behavior, meaning, it hides warnings and hides messages when rendering. editor: visual Uses the visual editor in Rstudio for the output Marks the end of the YAML header. As a whole, the YAML header looks like this: 5.6.4 Quarto Key Features Code Chunks Code chunks allow you to include and run code inside your document. To make code chunks, long way (there is shortcut later). Type ```{r} then press Enter. If you want to run the specific code chunk, you can also press the green play button at the right side of the chunk. If you want to run previous code chunks, press the button that has an arrow down with a green line below, just beside the green play button. jem&lt;-15+50+143 Inline Code Embed R code in text using backticks and r . Try typing this: The total number of pairs is “r 15+12”. Replace the quotation marks with backticks. When you render the file, what should come out in place of the backticks thing would be the number 27. 5.6.5 Quarto Markdown Shortcuts Action Windows Shortcut Mac Shortcut Insert a new code chunk Ctrl+Alt+I Cmd+Option+I Run current code chunk Ctrl+Shift+Enter Cmd+Shift+Enter Run all code chunks Ctrl+Alt+R Cmd+Alt+R Run current line/selection Ctrl+Enter Cmd+Enter Knit/Render document Ctrl+Shift+K Cmd+Shift+K Comment/uncomment lines Ctrl+Shift+C Cmd+Shift+C Insert pipe (%&gt;%) Ctrl+Shift+M Cmd+Shift+M Headings /H Number of Heading (if in Visual mode) Prefix line with #, ##, etc. manually (in Source mode) /H Number of Heading (if in Visual mode) Prefix line with #, ##, etc. manually (in Source mode) Bold Ctrl+B Cmd+B Italic Ctrl+I Cmd+I Inline code Surround with backticks (’) manually Surround with backticks (’) manually 5.6.6 Rendering a Quarto Document Rendering is the process of turning your .qmd file into an html. No rendering done, no submission. In this course, you will primarily render to HTML. 5.6.6.1 Render Using RStudio Button (DO THIS) Open your qmd file Make sure it is saved in the working directory Click Render button at the top of the editor. It looks like a blue arrow with the word Render. RStudio will run all code chunks, convert the document to HTML then open the result in the Viewer pane. If the render is successful, an html file will appear in your Files tab. You can double-click on the html file in your Files so that it appears in a bigger window which you can use to print as PDF. 5.7 Working Directories and File Management You will always work locally first. Each student must: Edit .qmd files only inside their local DLSU_COURSE_Section folder. Render HTML files locally to check for errors Never edit files directly inside Google Drive via a browser 5.7.1 File Naming Convention (Mandatory) To avoid confusion, all .qmd files must follow this format: initials_topic.qmd Example: jmn_descriptives.qmd jmn_visualization.qmd/ 5.8 Mini-Exercise: First Quarto Render (Mandatory per Individual) This exercise checks that you can write, run, and render a Quarto document correctly. Instructions: Create a new Quarto HTML document in RStudio. Keep the YAML header exactly as shown earlier in this chapter. In the body of the document, do the following steps: a. Add a Section Header Below the YAML header, add the following Markdown header: About Me as Heading 1 Under this header, write 2-3 sentences introducing yourself (name, program, year, hobbies) b. Add Inline Code for your age In the same section, add a sentence that includes inline R code. Sentence: I am “r 2026-type your year of birth” years old. Do NOT calculate your age manually. The age must be computed by R. The number should appear as plain text in the sentence. c. Add a Code Chunk Insert a new R code chunk. Inside the chunk: Add a comment saying this is just a test Create an object named after your initials Add the alphabetical positions of your initials Print the result Example: #This is just a test jmn&lt;-10+13+14 print(jmn) ## [1] 37 d. Render the document This exercise will help you in future lectures! e. Create a new Quarto document Clean the environment and free up the memory. Don’t forget your YAML header before the code chunk including the cleaning and freeing the memory! "],["data-management---cross-sectional-data.html", "6 Data Management - Cross-Sectional Data 6.1 Where to Get Data? 6.2 Preliminaries 6.3 Data Cleaning 6.4 Closing", " 6 Data Management - Cross-Sectional Data 6.1 Where to Get Data? Before we proceed to Data Management, let us first find where we can get data for the Data Story Archive. Note that the data you collect should still ensure that you are following the Code of Ethics and analyze Ethical Considerations. Please view the necessary documents from the Office of the Vice Chancellor for Research and Innovation (https://www.dlsu.edu.ph/research/research-manual/) A list of links you can search and get data from: Note: I will not include the best links as they are pretty straightforward and these are governmental databases like the ones from World Bank, IMF, UN, Philippine Statistics Authority, and Bangko Sentral ng Pilipinas. The list here is a general list but use with proper discretion. Name Link Notes Awesome Public Datasets https://github.com/awesomedata/awesome-public-datasets This repository is filled with public datasets, mostly from International contexts. Google Dataset Search https://datasetsearch.research.google.com/ You can download publicly available datasets from searching through Google. Though, sometimes the datasets come from ‘Statista.com’. You can check the sources from the search. 6.2 Preliminaries 6.2.1 Packages We will mostly use the tidyverse package, in particular, the dplyr package and the tidyr package; double-check in your Packages list whether you have these two packages; if not, you can simply install them. 6.2.2 Clean Everything Do this step every time you use other data or when we do the other chapters. # Remove all objects in the global environment rm(list = ls()) # Perform garbage collection to free up memory gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 1286445 68.8 2599520 138.9 2457758 131.3 ## Vcells 3122755 23.9 8388608 64.0 8388604 64.0 6.2.3 Importing the Datasets Before we can manage the data, we must first import it into R. There are two ways to do this: Writing code (preferred for replicability) Clicking in RStudio We start with the most common file types. 6.2.3.1 Importing a CSV file cp_csv&lt;-read.csv(&quot;CP_1.csv&quot;) The file must be in the working directory. If it is not, then, simply putting the file name inside the quotation marks will not work. Meaning, you have to input the entire path where the file is. Another, if you notice, the CSV file name is simple and easy to share. The object, in this case, cp_csv is also in small letters and does not have spaces but rather an underscore replacing the space. Always do this when naming objects. a. Small letters b. No spaces c. Place underscore instead. To check the information and what the dataset looks like: head(cp_csv) ## Country ID HH1_Num_People HH2a_Sex HH2b_Age HH2d_EmploymentSituation Q1_PaidJob ## 1 Bulgaria BG1535216 3 Female 56 Unemployed less than 12 months Yes ## 2 Netherlands NL5130211 1 Female 20 In education (at school, university, etc.) / student Yes ## 3 Netherlands NL5063519 2 Male 63 Retired Yes ## 4 Slovenia SI1042916 3 Male 63 At work as employee or employer/self-employed &lt;NA&gt; ## 5 Bulgaria BG1396625 2 Male 89 Retired Yes ## 6 Slovakia SK1184115 2 Female 44 At work as employee or employer/self-employed &lt;NA&gt; ## Q2_Empoyment Q3_Contract Q4_Occupation Q7_HoursWeekWork Q7a_AdditionalJob ## 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA &lt;NA&gt; ## 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA &lt;NA&gt; ## 4 Employed On an unlimited permanent contract Technician or junior professional 35 No ## 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA &lt;NA&gt; ## 6 Self-employed without employees On an unlimited permanent contract Technician or junior professional 43 No ## Q7b_HoursWeekWeekAddJob Q7c_Work Q8_HoursWeekWorkPref Q9_HoursWeekWorkPartner Q10_HoursWeekWorkPartnerPref Q17_Rooms ## 1 NA No 40 40 4 3 ## 2 NA No 10 NA NA 1 ## 3 NA No 0 NA 0 6 ## 4 NA &lt;NA&gt; 30 NA 30 3 ## 5 NA No 0 NA 0 1 ## 6 NA &lt;NA&gt; 43 NA NA 2 ## Q18_Tenancy Q19a_ShortageSpace Q19b_Rot Q19c_Leaks Q19d_NoFlusingToilet Q19e_NoBathShower Q19f_NoOutside ## 1 Own without mortgage 0 0 0 0 0 0 ## 2 Other 0 0 0 0 0 0 ## 3 Own with mortgage 0 0 0 0 0 0 ## 4 Tenant, paying rent to private landlord 0 0 0 0 0 0 ## 5 Own without mortgage 0 0 0 0 0 0 ## 6 Own without mortgage 1 0 0 0 0 0 ## Q20_LeaveAccomodation_NoAff Q24_Trust Q25a_TensionClass Q25b_TensionWork Q25c_TensionSex Q25d_TensionsAge ## 1 Very unlikely 6 Some tension No tension No tension 3 ## 2 Quite unlikely 6 Some tension Some tension No tension 3 ## 3 Very unlikely 8 Some tension Some tension No tension 3 ## 4 Quite unlikely 6 Some tension Some tension No tension 3 ## 5 Very unlikely 1 - you can&#39;t be too careful Some tension Don”t know Some tension 2 ## 6 Very likely 5 Some tension Some tension Some tension 2 ## Q25e_TensionRace Q25f_TensionReligion Q25g_TensionSexOrient Q37a_HoursWeekChildren Q37b_HoursWeekHousework Q37c_HoursWeekElderly ## 1 Some tension No tension No tension 2 14 NA ## 2 Some tension Some tension A lot of tension NA 7 NA ## 3 A lot of tension A lot of tension Some tension NA 14 3 ## 4 Some tension Some tension No tension 5 NA NA ## 5 Don”t know Don”t know Don”t know NA NA NA ## 6 Some tension Some tension Some tension NA 20 NA ## Q48_Education Q49_Area Q50a_NeighbourhoodNoise Q50b_NeighbourhoodAir Q50c_NeighbourhoodWater Q50d_NeighbourhoodCrime ## 1 1250 A medium to large town No problems No problems Major problems No problems ## 2 2956 A city or city suburb No problems No problems No problems No problems ## 3 2963 A medium to large town No problems No problems No problems No problems ## 4 3420 A medium to large town No problems No problems No problems No problems ## 5 1253 A city or city suburb No problems No problems No problems Moderate problems ## 6 3530 A medium to large town No problems No problems No problems No problems ## Q50e_NeighbourhoodLitter Q50f_NeighbourhoodTraffic Q51a_AccServicesPost Q51b_AccServicesBank Q53c_QualityPublicTransport Income_PPP ## 1 No problems No problems Service not used Easily 6 NA ## 2 No problems No problems Easily With some difficulty 7 273.4731 ## 3 No problems No problems Easily Easily 7 3190.5196 ## 4 No problems Moderate problems Easily Easily 6 4171.6329 ## 5 Moderate problems Don&#39;t know Service not used Service not used 3 478.3407 ## 6 No problems Moderate problems Very easily Very easily 5 759.6961 str(cp_csv) ## &#39;data.frame&#39;: 4036 obs. of 49 variables: ## $ Country : chr &quot;Bulgaria&quot; &quot;Netherlands&quot; &quot;Netherlands&quot; &quot;Slovenia&quot; ... ## $ ID : chr &quot;BG1535216&quot; &quot;NL5130211&quot; &quot;NL5063519&quot; &quot;SI1042916&quot; ... ## $ HH1_Num_People : int 3 1 2 3 2 2 2 1 4 2 ... ## $ HH2a_Sex : chr &quot;Female&quot; &quot;Female&quot; &quot;Male&quot; &quot;Male&quot; ... ## $ HH2b_Age : int 56 20 63 63 89 44 52 43 47 81 ... ## $ HH2d_EmploymentSituation : chr &quot;Unemployed less than 12 months&quot; &quot;In education (at school, university, etc.) / student&quot; &quot;Retired&quot; &quot;At work as employee or employer/self-employed&quot; ... ## $ Q1_PaidJob : chr &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; NA ... ## $ Q2_Empoyment : chr NA NA NA &quot;Employed&quot; ... ## $ Q3_Contract : chr NA NA NA &quot;On an unlimited permanent contract&quot; ... ## $ Q4_Occupation : chr NA NA NA &quot;Technician or junior professional&quot; ... ## $ Q7_HoursWeekWork : int NA NA NA 35 NA 43 NA NA 17 NA ... ## $ Q7a_AdditionalJob : chr NA NA NA &quot;No&quot; ... ## $ Q7b_HoursWeekWeekAddJob : int NA NA NA NA NA NA NA NA NA NA ... ## $ Q7c_Work : chr &quot;No&quot; &quot;No&quot; &quot;No&quot; NA ... ## $ Q8_HoursWeekWorkPref : int 40 10 0 30 0 43 40 40 35 0 ... ## $ Q9_HoursWeekWorkPartner : int 40 NA NA NA NA NA 41 NA 35 NA ... ## $ Q10_HoursWeekWorkPartnerPref: int 4 NA 0 30 0 NA 30 NA 35 0 ... ## $ Q17_Rooms : int 3 1 6 3 1 2 NA 1 5 3 ... ## $ Q18_Tenancy : chr &quot;Own without mortgage&quot; &quot;Other&quot; &quot;Own with mortgage&quot; &quot;Tenant, paying rent to private landlord&quot; ... ## $ Q19a_ShortageSpace : int 0 0 0 0 0 1 0 0 0 0 ... ## $ Q19b_Rot : int 0 0 0 0 0 0 0 1 1 0 ... ## $ Q19c_Leaks : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q19d_NoFlusingToilet : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q19e_NoBathShower : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q19f_NoOutside : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q20_LeaveAccomodation_NoAff : chr &quot;Very unlikely&quot; &quot;Quite unlikely&quot; &quot;Very unlikely&quot; &quot;Quite unlikely&quot; ... ## $ Q24_Trust : chr &quot;6&quot; &quot;6&quot; &quot;8&quot; &quot;6&quot; ... ## $ Q25a_TensionClass : chr &quot;Some tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; ... ## $ Q25b_TensionWork : chr &quot;No tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; ... ## $ Q25c_TensionSex : chr &quot;No tension&quot; &quot;No tension&quot; &quot;No tension&quot; &quot;No tension&quot; ... ## $ Q25d_TensionsAge : int 3 3 3 3 2 2 98 3 3 1 ... ## $ Q25e_TensionRace : chr &quot;Some tension&quot; &quot;Some tension&quot; &quot;A lot of tension&quot; &quot;Some tension&quot; ... ## $ Q25f_TensionReligion : chr &quot;No tension&quot; &quot;Some tension&quot; &quot;A lot of tension&quot; &quot;Some tension&quot; ... ## $ Q25g_TensionSexOrient : chr &quot;No tension&quot; &quot;A lot of tension&quot; &quot;Some tension&quot; &quot;No tension&quot; ... ## $ Q37a_HoursWeekChildren : int 2 NA NA 5 NA NA 4 NA NA NA ... ## $ Q37b_HoursWeekHousework : int 14 7 14 NA NA 20 4 8 4 6 ... ## $ Q37c_HoursWeekElderly : int NA NA 3 NA NA NA NA NA NA NA ... ## $ Q48_Education : chr &quot;1250&quot; &quot;2956&quot; &quot;2963&quot; &quot;3420&quot; ... ## $ Q49_Area : chr &quot;A medium to large town&quot; &quot;A city or city suburb&quot; &quot;A medium to large town&quot; &quot;A medium to large town&quot; ... ## $ Q50a_NeighbourhoodNoise : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50b_NeighbourhoodAir : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50c_NeighbourhoodWater : chr &quot;Major problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50d_NeighbourhoodCrime : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50e_NeighbourhoodLitter : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50f_NeighbourhoodTraffic : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;Moderate problems&quot; ... ## $ Q51a_AccServicesPost : chr &quot;Service not used&quot; &quot;Easily&quot; &quot;Easily&quot; &quot;Easily&quot; ... ## $ Q51b_AccServicesBank : chr &quot;Easily&quot; &quot;With some difficulty&quot; &quot;Easily&quot; &quot;Easily&quot; ... ## $ Q53c_QualityPublicTransport : chr &quot;6&quot; &quot;7&quot; &quot;7&quot; &quot;6&quot; ... ## $ Income_PPP : num NA 273 3191 4172 478 ... The head code shows the first 6 rows and all the columns (variables) in the dataset. Meanwhile the str code shows the information of the dataset, such as what format type each column/variable is, how many observations, etc. B. Using RStudio Go to Environment Click Import Dataset Choose From Text (base) or From Test (readr) Click Browse and select your .csv file Click Import RStudio will load the dataset and generate R code in Console. Copy the R code to your script for reproducibility. 6.2.3.2 Importing an Excel File First, install and load the package: install.packages(&quot;readxl&quot;) library(readxl) cp_xlsx&lt;-read_excel(&quot;CP_1.xlsx&quot;) If you only want a particular sheet to be imported, cp_xlsx&lt;-read_excel(&quot;CP_1.xlsx&quot;, sheet= 1) head(cp_xlsx) ## # A tibble: 6 × 49 ## Country ID HH1_Num_People HH2a_Sex HH2b_Age HH2d_EmploymentSitua…¹ Q1_PaidJob Q2_Empoyment Q3_Contract Q4_Occupation Q7_HoursWeekWork ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Bulgaria BG15… 3 Female 56 Unemployed less than … Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 2 Netherlands NL51… 1 Female 20 In education (at scho… Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 3 Netherlands NL50… 2 Male 63 Retired Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 4 Slovenia SI10… 3 Male 63 At work as employee o… &lt;NA&gt; Employed On an unli… Technician o… 35 ## 5 Bulgaria BG13… 2 Male 89 Retired Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 6 Slovakia SK11… 2 Female 44 At work as employee o… &lt;NA&gt; Self-employ… On an unli… Technician o… 43 ## # ℹ abbreviated name: ¹​HH2d_EmploymentSituation ## # ℹ 38 more variables: Q7a_AdditionalJob &lt;chr&gt;, Q7b_HoursWeekWeekAddJob &lt;dbl&gt;, Q7c_Work &lt;chr&gt;, Q8_HoursWeekWorkPref &lt;dbl&gt;, ## # Q9_HoursWeekWorkPartner &lt;dbl&gt;, Q10_HoursWeekWorkPartnerPref &lt;dbl&gt;, Q17_Rooms &lt;dbl&gt;, Q18_Tenancy &lt;chr&gt;, Q19a_ShortageSpace &lt;dbl&gt;, ## # Q19b_Rot &lt;dbl&gt;, Q19c_Leaks &lt;dbl&gt;, Q19d_NoFlusingToilet &lt;dbl&gt;, Q19e_NoBathShower &lt;dbl&gt;, Q19f_NoOutside &lt;dbl&gt;, ## # Q20_LeaveAccomodation_NoAff &lt;chr&gt;, Q24_Trust &lt;chr&gt;, Q25a_TensionClass &lt;chr&gt;, Q25b_TensionWork &lt;chr&gt;, Q25c_TensionSex &lt;chr&gt;, ## # Q25d_TensionsAge &lt;chr&gt;, Q25e_TensionRace &lt;chr&gt;, Q25f_TensionReligion &lt;chr&gt;, Q25g_TensionSexOrient &lt;chr&gt;, Q37a_HoursWeekChildren &lt;dbl&gt;, ## # Q37b_HoursWeekHousework &lt;dbl&gt;, Q37c_HoursWeekElderly &lt;dbl&gt;, Q48_Education &lt;chr&gt;, Q49_Area &lt;chr&gt;, Q50a_NeighbourhoodNoise &lt;chr&gt;, … B. Using RStudio Go to Environment Click Import Dataset Choose From Excel Click Browse and select your .xlsx file Choose the sheet Click Import Check that you also have the variables as the header. 6.2.3.3 Importing RData These files are native to R and can contain multiple objects. load(&quot;Dataset_CP.RData&quot;) head(Dataset_CP) ## # A tibble: 6 × 49 ## Country ID HH1_Num_People HH2a_Sex HH2b_Age HH2d_EmploymentSitua…¹ Q1_PaidJob Q2_Empoyment Q3_Contract Q4_Occupation Q7_HoursWeekWork ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Bulgaria BG15… 3 Female 56 Unemployed less than … Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 2 Netherlands NL51… 1 Female 20 In education (at scho… Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 3 Netherlands NL50… 2 Male 63 Retired Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 4 Slovenia SI10… 3 Male 63 At work as employee o… &lt;NA&gt; Employed On an unli… Technician o… 35 ## 5 Bulgaria BG13… 2 Male 89 Retired Yes &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 6 Slovakia SK11… 2 Female 44 At work as employee o… &lt;NA&gt; Self-employ… On an unli… Technician o… 43 ## # ℹ abbreviated name: ¹​HH2d_EmploymentSituation ## # ℹ 38 more variables: Q7a_AdditionalJob &lt;fct&gt;, Q7b_HoursWeekWeekAddJob &lt;dbl&gt;, Q7c_Work &lt;fct&gt;, Q8_HoursWeekWorkPref &lt;dbl&gt;, ## # Q9_HoursWeekWorkPartner &lt;dbl&gt;, Q10_HoursWeekWorkPartnerPref &lt;dbl&gt;, Q17_Rooms &lt;dbl&gt;, Q18_Tenancy &lt;fct&gt;, Q19a_ShortageSpace &lt;dbl&gt;, ## # Q19b_Rot &lt;dbl&gt;, Q19c_Leaks &lt;dbl&gt;, Q19d_NoFlusingToilet &lt;dbl&gt;, Q19e_NoBathShower &lt;dbl&gt;, Q19f_NoOutside &lt;dbl&gt;, ## # Q20_LeaveAccomodation_NoAff &lt;fct&gt;, Q24_Trust &lt;fct&gt;, Q25a_TensionClass &lt;fct&gt;, Q25b_TensionWork &lt;fct&gt;, Q25c_TensionSex &lt;fct&gt;, ## # Q25d_TensionsAge &lt;hvn_lbl_&gt;, Q25e_TensionRace &lt;fct&gt;, Q25f_TensionReligion &lt;fct&gt;, Q25g_TensionSexOrient &lt;fct&gt;, ## # Q37a_HoursWeekChildren &lt;dbl&gt;, Q37b_HoursWeekHousework &lt;dbl&gt;, Q37c_HoursWeekElderly &lt;dbl&gt;, Q48_Education &lt;fct&gt;, Q49_Area &lt;fct&gt;, … B. Using RStudio Environment panel Click Import Dataset Choose From RData Select the .RData file Click Import 6.3 Data Cleaning As you can see, there are 49 columns. Let’s simplify and work with fewer variables relevant for analysis. We can do this using the select() function in dplyr. We will save them into a new data frame, ch2_p1.1. library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union ch2_p1.1&lt;-select(cp_csv, Country, ID, HH2a_Sex, HH2b_Age, Q1_PaidJob, Q7_HoursWeekWork, Q17_Rooms, Q49_Area, Income_PPP) select(df, var1, var2,...) keeps only the listed columns and removes the rest. 6.3.1 Renaming the Variables We will edit the names to much easier conventions. First, let us say that we just want to change them to lowercase names. names(ch2_p1.1)&lt;-tolower(names(ch2_p1.1)) Inspect: head(ch2_p1.1) ## country id hh2a_sex hh2b_age q1_paidjob q7_hoursweekwork q17_rooms q49_area income_ppp ## 1 Bulgaria BG1535216 Female 56 Yes NA 3 A medium to large town NA ## 2 Netherlands NL5130211 Female 20 Yes NA 1 A city or city suburb 273.4731 ## 3 Netherlands NL5063519 Male 63 Yes NA 6 A medium to large town 3190.5196 ## 4 Slovenia SI1042916 Male 63 &lt;NA&gt; 35 3 A medium to large town 4171.6329 ## 5 Bulgaria BG1396625 Male 89 Yes NA 1 A city or city suburb 478.3407 ## 6 Slovakia SK1184115 Female 44 &lt;NA&gt; 43 2 A medium to large town 759.6961 Inspect again on your own. Let us rename specific columns: ch2_p1.1&lt;-ch2_p1.1 %&gt;% rename( sex = hh2a_sex, age = hh2b_age, paid_job = q1_paidjob, hours_work = q7_hoursweekwork, rooms = q17_rooms, area = q49_area, income = income_ppp ) Inspect on your own. names() simply gets or sets variable names. tolower is to simply change to small letters rename(new_name = old_name) changes a column’s name without touching data %&gt;% is the pipe operator: it passes the dataset from one function to the next. 6.3.2 Sorting Variables Let’s say, we want to arrange income. We will create a different data for this. We use arrange or desc in dplyr package #Sort dataset by income, ascending (default) ch2_p1sort&lt;-arrange(ch2_p1.1, income) #Sort dataset by income, descending ch2_p1sort_desc&lt;-arrange(ch2_p1.1, desc(income)) Inspect on your own. 6.3.2.1 Making our own data frame ch2_p2&lt;-data.frame( ch2_p2 = as.factor(c(&quot;$10,000&quot;, &quot;$20,500&quot;, &quot;$15,250&quot;, &quot;$30,000&quot;, &quot;$50,750&quot;)) ) c() stands for combine. We’re creating a vector of values. as.factor() converts the vector into a factor, that is a categorical variable not numbers. data.frame(...) creates a dataset in R. head(ch2_p2) ## ch2_p2 ## 1 $10,000 ## 2 $20,500 ## 3 $15,250 ## 4 $30,000 ## 5 $50,750 Let’s sort this: ch2_p2sort&lt;-arrange(ch2_p2) head(ch2_p2) ## ch2_p2 ## 1 $10,000 ## 2 $20,500 ## 3 $15,250 ## 4 $30,000 ## 5 $50,750 It did not work. The problem is, ch2_p2 is not numeric. We can check: class(ch2_p2$ch2_p2) ## [1] &quot;factor&quot; We need to make it into a numeric value but we have a , and $. We need to remove them. We use the str_replace function in the stringr package. library(stringr) ch2_p2$ch2_p2&lt;-str_replace( ch2_p2$ch2_p2, #column we want to edit pattern = &#39;,&#39;, #what to find replacement = &#39;&#39; #what to replace it with ) head(ch2_p2) ## ch2_p2 ## 1 $10000 ## 2 $20500 ## 3 $15250 ## 4 $30000 ## 5 $50750 Now, let us remove the dollar sign; usually, simply doing the same thing we did with the comma works, but, there are some symbols that are used as “special character”. To “force” R to replace the presence of ‘$’, we add two backslashes before the dollar sign. ch2_p2$ch2_p2&lt;-str_replace( ch2_p2$ch2_p2, pattern = &#39;\\\\$&#39;, replacement = &#39;&#39; ) Inspect on your own. Now, sort ch2_p2 on your own. We can see that it was arranged, however, take a look at the way ch2_p2 was encoded; it is not numeric. So, we need to change this. class(ch2_p2$ch2_p2) ## [1] &quot;character&quot; Change to numeric through as.numeric() ch2_p2$ch2_p2&lt;-as.numeric(ch2_p2$ch2_p2) Inspect on your own. 6.3.3 Pipe Operator %&gt;% allows functions to be chained; it can be read as “then” - it tells R to do whatever comes after it to the stuff that comes before it. ch2_p1.1.2 &lt;- ch2_p1.1 %&gt;% filter(age &gt; 60) %&gt;% arrange(desc(income)) Inspect on your own. 6.3.4 Adding columns We will be using the pipe operator and the mutate to add a new column to ch2_p1.1 ch2_p1.1 &lt;- ch2_p1.1 %&gt;% mutate( #adds a new column to the dataset room_group = case_when( #checks each row&#39;s value and assigned a category rooms == 1 ~ &quot;one_room&quot;, rooms == 2 ~ &quot;two_rooms&quot;, rooms == 3 ~ &quot;three_rooms&quot;, rooms == 4 ~ &quot;four_rooms&quot;, rooms == 5 ~ &quot;five_rooms&quot;, rooms == 6 ~ &quot;six_rooms&quot;, rooms == 7 ~ &quot;seven_rooms&quot;, rooms == 8 ~ &quot;eight_rooms&quot;, rooms == 9 ~ &quot;nine_rooms&quot;, rooms == 10 ~ &quot;ten_rooms&quot;, rooms == 11 ~ &quot;eleven_rooms&quot;, rooms == 12 ~ &quot;twelve_rooms&quot;, TRUE ~ &quot;other&quot; # anything outside 1–12 or missing ) ) 6.3.5 Transforming Values Now, you can see that paid_job is a character that is “yes/no”. We need to change that to numeric value. This is particularly useful when we use dummy variables later on. We will not use case_when as it is not necessary; rather, we will use ifelse: ch2_p1.1&lt;-ch2_p1.1 %&gt;% mutate( paid_job = ifelse(paid_job == &quot;Yes&quot;, 1, 0) ) 6.3.6 Categorizing into groups We use the case_when(): ch2_p1.1 &lt;- ch2_p1.1 %&gt;% mutate( age_group = case_when( age &gt;= 18 &amp; age &lt;= 29 ~ &quot;young&quot;, # 18–29 years age &gt;= 30 &amp; age &lt;= 59 ~ &quot;adult&quot;, # 30–59 years age &gt;= 60 ~ &quot;older_adult&quot;, # 60+ years TRUE ~ &quot;other&quot; # NA ) ) mutate() adding new column The conditions are important. 6.3.7 Summarizing Let us get the average of income by age group, which we’ll call ave_income, by using the group_by() and summarise() functions in dplyr ch2_p1.1ave&lt;-ch2_p1.1 %&gt;% group_by(age_group) %&gt;% #group by age group, THEN summarise(ave_income=mean(income)) #calculate the mean of income for each age group head(ch2_p1.1ave) ## # A tibble: 3 × 2 ## age_group ave_income ## &lt;chr&gt; &lt;dbl&gt; ## 1 adult NA ## 2 older_adult NA ## 3 young NA How did this happen? It is because there are NAs in income. Let’s check for NAs in our dataset colSums(is.na(ch2_p1.1)) ## country id sex age paid_job hours_work rooms area income room_group age_group ## 0 0 0 0 1768 2304 25 0 978 0 0 There are 978 NAs in income, that is why the average income is NA. For the sake of, let’s remove the NA. ch2_p1.1ave &lt;- ch2_p1.1 %&gt;% group_by(age_group) %&gt;% summarise(ave_income = mean(income, na.rm = TRUE)) head(ch2_p1.1ave) ## # A tibble: 3 × 2 ## age_group ave_income ## &lt;chr&gt; &lt;dbl&gt; ## 1 adult 2145. ## 2 older_adult 1566. ## 3 young 1809. The difference is the inclusion of na.rm = TRUE which means we remove the missing values when calculating the mean. So, even though we know income is numeric, the presence of NA causes the output when calculating mean, sd, etc. become NA too. 6.3.8 Merging datasets We have two main datasets, ch2_p1.1 and ch2_p1.1ave. By doing this, we could compare side-by-side each observation compared to the average per age group. We will join the datasets by age_group variable, since that is consistent across both datasets. We name the new file as ch2_p1merged: ch2_p1merged&lt;-merge(x=ch2_p1.1, y=ch2_p1.1ave, by=&quot;age_group&quot;) head(ch2_p1merged) ## age_group country id sex age paid_job hours_work rooms area income room_group ave_income ## 1 adult Bulgaria BG1535216 Female 56 1 NA 3 A medium to large town NA three_rooms 2145.059 ## 2 adult Hungary HU1042815 Male 39 0 NA 2 A village/small town 987.0490 two_rooms 2145.059 ## 3 adult Poland PL1229721 Female 47 NA 40 4 A village/small town 1722.0737 four_rooms 2145.059 ## 4 adult Germany DE1045717 Female 56 1 NA 3 A city or city suburb NA three_rooms 2145.059 ## 5 adult Finland FI1024310 Male 58 NA 32 5 A medium to large town 3958.9271 five_rooms 2145.059 ## 6 adult Slovakia SK1184115 Female 44 NA 43 2 A medium to large town 759.6961 two_rooms 2145.059 6.3.9 Splitting datasets Say I want to save different datasets based on the age_group column. adult_data&lt;-ch2_p1.1 %&gt;% filter(age_group==&quot;adult&quot;) filter() keeps rows that meet the condition. You can save it as a .csv file: write.csv(adult_data, &quot;adult_data.csv&quot;, row.names = FALSE) Can you do the others? (young or older_adult) 6.3.10 Reshaping Datasets Let’s say you want to reshape income and hours_work into a long format so every row is a variable measurement. We need both tidyr and dplyr packages. 6.3.10.1 Long Format library(tidyr) library(dplyr) ch2_long&lt;-ch2_p1.1 %&gt;% pivot_longer( cols = c(hours_work, income), # columns to stack names_to = &quot;variable&quot;, #new column for variable names values_to = &quot;value&quot; #new column for their values ) head(ch2_long) ## # A tibble: 6 × 11 ## country id sex age paid_job rooms area room_group age_group variable value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Bulgaria BG1535216 Female 56 1 3 A medium to large town three_rooms adult hours_work NA ## 2 Bulgaria BG1535216 Female 56 1 3 A medium to large town three_rooms adult income NA ## 3 Netherlands NL5130211 Female 20 1 1 A city or city suburb one_room young hours_work NA ## 4 Netherlands NL5130211 Female 20 1 1 A city or city suburb one_room young income 273. ## 5 Netherlands NL5063519 Male 63 1 6 A medium to large town six_rooms older_adult hours_work NA ## 6 Netherlands NL5063519 Male 63 1 6 A medium to large town six_rooms older_adult income 3191. pivot_longer() turns columns into rows 6.3.10.2 Wide Format ch2_wide&lt;-ch2_long %&gt;% pivot_wider( names_from = variable, #column to spread to multiple columns values_from = value #value to fill columns ) head(ch2_wide) ## # A tibble: 6 × 11 ## country id sex age paid_job rooms area room_group age_group hours_work income ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Bulgaria BG1535216 Female 56 1 3 A medium to large town three_rooms adult NA NA ## 2 Netherlands NL5130211 Female 20 1 1 A city or city suburb one_room young NA 273. ## 3 Netherlands NL5063519 Male 63 1 6 A medium to large town six_rooms older_adult NA 3191. ## 4 Slovenia SI1042916 Male 63 NA 3 A medium to large town three_rooms older_adult 35 4172. ## 5 Bulgaria BG1396625 Male 89 1 1 A city or city suburb one_room older_adult NA 478. ## 6 Slovakia SK1184115 Female 44 NA 2 A medium to large town two_rooms adult 43 760. Say you want to analyze repeated categories or measures. We can pivot the room_group and age_group to long: ch2_long2&lt;-ch2_p1.1 %&gt;% pivot_longer( cols = c(room_group, age_group), names_to = &quot;category&quot;, values_to = &quot;group&quot; ) head(ch2_long2) ## # A tibble: 6 × 11 ## country id sex age paid_job hours_work rooms area income category group ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bulgaria BG1535216 Female 56 1 NA 3 A medium to large town NA room_group three_rooms ## 2 Bulgaria BG1535216 Female 56 1 NA 3 A medium to large town NA age_group adult ## 3 Netherlands NL5130211 Female 20 1 NA 1 A city or city suburb 273. room_group one_room ## 4 Netherlands NL5130211 Female 20 1 NA 1 A city or city suburb 273. age_group young ## 5 Netherlands NL5063519 Male 63 1 NA 6 A medium to large town 3191. room_group six_rooms ## 6 Netherlands NL5063519 Male 63 1 NA 6 A medium to large town 3191. age_group older_adult 6.3.11 Missing Values We already did it before but just to remind: #Count missing values per column colSums(is.na(ch2_p1.1)) ## country id sex age paid_job hours_work rooms area income room_group age_group ## 0 0 0 0 1768 2304 25 0 978 0 0 When there are missing values, it reduces sample size, can bias estimates if the missingness is not random and may introduce endogeneity if the missing data is correlated with the outcome or other variables. 6.3.11.1 Types of Missing Data MCAR - Missing Completely at Random Missingness is unrelated to anything in the data MAR - Missing at Random Missingness depends on observed variables but not on the missing value itself. Example: younger respondents are less likely to report income. MNAR - Missing Not at Random Missingness depends on the value itself Example: high income people refuse to report income If you have MCAR, safe to remove this. If MAR or MNAR, removing these can cause bias. If a variable with missing values affects the outcome and you remove it or impute incorrectly, you can create endogeneity. 6.3.11.2 Handling Missing Values 6.3.11.2.1 a. Remove missing observations #Keep only rows without missing income ch2_p1.2&lt;-ch2_p1.1 %&gt;% filter(!is.na(income)) !is.na() means you are keeping rows WITHOUT missing income Again, double-check because removing the missing values may bias your results 6.3.11.2.2 b. Replace missing values (imputation of mean/median) #replace missing income with the mean ch2_p1.3&lt;-ch2_p1.1 %&gt;% mutate(income=ifelse(is.na(income), mean(income, na.rm=TRUE), income)) ifelse(condition, value_if_true, value_if_false) in this case, you are telling R to search income’s NA values, if there are NA values, calculate the mean income without the NAs. then, change the NAs with the calculated mean income, otherwise, keep the income as is. There are advanced methods but will not be discussed. You have to be careful and always check for missing data. 6.4 Closing Quiz questions will be uploaded in Animospace. You have 15 minutes to answer. Clean the environment and free the memory. "],["data-management---time-series-and-panel-data.html", "7 Data Management - Time Series and Panel Data 7.1 Time Series Data 7.2 Panel Data 7.3 Closing", " 7 Data Management - Time Series and Panel Data 7.1 Time Series Data Time series analysis requires correct date formats, proper chronological ordering, etc. For this, we will use Chapter3 Practice found in the Modules. 7.1.1 Preliminaries Always remember the first steps: Set Working Directory and Clean the Global Environment. rm(list=ls()) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 1501387 80.2 2599520 138.9 2599520 138.9 ## Vcells 3508493 26.8 8388608 64.0 8388604 64.0 To make sure that you are using the correct directory and that you have all the files you need, use list.files() function. list.files() Now, we load the following packages: dplyr, lubridate, and zoo. Make sure you have all 3 installed; if not, install them. library(dplyr) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(zoo) ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric 7.1.2 Create a Simple Date Dataset date_date&lt;-data.frame( ID = 1:5, dob = c(&quot;15-05-1990&quot;, &quot;20-08-1985&quot;, &quot;01-12-2000&quot;, &quot;10-03-1995&quot;, &quot;25-07-2010&quot;), stringsAsFactors = FALSE ) print(date_date) ## ID dob ## 1 1 15-05-1990 ## 2 2 20-08-1985 ## 3 3 01-12-2000 ## 4 4 10-03-1995 ## 5 5 25-07-2010 str(date_date) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ ID : int 1 2 3 4 5 ## $ dob: chr &quot;15-05-1990&quot; &quot;20-08-1985&quot; &quot;01-12-2000&quot; &quot;10-03-1995&quot; ... I won’t repeat what the code has except for new ones like ID which creates a numeric sequence for the ID column. date_of_birth = c(\"15-05-1990\",...) are dates stored as character strings. stringsAsFactors = FALSE because R sometimes turns text into factors (categories) so by making it FALSE, it ensures dates remain character strings not categories As seen, the dob is in character format: 7.1.3 Converting Character Dates to Date Format date_date$dob&lt;- as.Date( date_date$dob, format = &quot;%d-%m-%Y&quot; ) class(date_date$dob) ## [1] &quot;Date&quot; So, we converted character strings into Date objects. With this, we can calculate age, lags, etc. 7.1.4 Calculate Age: Say you want to calculate the age: Before, we added columns through mutate; this time, we add columns through creating a new object. date_date$age &lt;- as.numeric(floor((Sys.Date()-date_date$dob)/365.25)) as.Date() converts strings to dates while floor() simply rounds down. 7.1.4.1 Custom Reference Date: ref_date&lt;-as.Date(&quot;2020-12-20&quot;) #uses YYYY-MM-DD as ISO standard that R recognizes immediately date_date$age2&lt;- as.numeric( floor((ref_date-date_date$dob)/365.25) ) 7.1.5 Using Time Series Data We load Daily Bitcoin Data ch3_p1&lt;-read.csv(&quot;Ch3Practice.csv&quot;) head(ch3_p1) ## ds y ## 1 2015-06-13 232.402 ## 2 2015-06-14 233.543 ## 3 2015-06-15 236.823 ## 4 2015-06-16 250.895 ## 5 2015-06-17 249.284 ## 6 2015-06-18 249.007 We need to understand our data; str(ch3_p1) ## &#39;data.frame&#39;: 1825 obs. of 2 variables: ## $ ds: chr &quot;2015-06-13&quot; &quot;2015-06-14&quot; &quot;2015-06-15&quot; &quot;2015-06-16&quot; ... ## $ y : num 232 234 237 251 249 ... 7.1.6 Convert to Date Format As you can see, our ds is what our date column is, however, it is in the character format. We need to convert it to the Date class. We also need to do this to a copy of the raw data for further modifications. ch3_p1.1&lt;-ch3_p1 head(ch3_p1.1$ds) ## [1] &quot;2015-06-13&quot; &quot;2015-06-14&quot; &quot;2015-06-15&quot; &quot;2015-06-16&quot; &quot;2015-06-17&quot; &quot;2015-06-18&quot; class(ch3_p1.1$ds) ## [1] &quot;character&quot; ch3_p1.1$ds &lt;- as.Date(ch3_p1.1$ds, format = &quot;%Y-%m-%d&quot;) class(ch3_p1.1$ds) ## [1] &quot;Date&quot; 7.1.7 Aggregate Data We now have daily data. Say we want to create weekly data, we use the cut function to group dates by week, month, quarter and year. Since we know for sure that the date column is in date format, no need to check, however, it is always useful to check the class of date. 7.1.7.1 Aggregate by Week Add new columns for each aggregation. ch3_p1.1$week&lt;-cut(ch3_p1.1$ds, breaks = &quot;week&quot;) The cut is used to divide the date into intervals while the breaks specifies that the date be divided into weekly intervals. Check creation of the week column head(ch3_p1.1) ## ds y week ## 1 2015-06-13 232.402 2015-06-08 ## 2 2015-06-14 233.543 2015-06-08 ## 3 2015-06-15 236.823 2015-06-15 ## 4 2015-06-16 250.895 2015-06-15 ## 5 2015-06-17 249.284 2015-06-15 ## 6 2015-06-18 249.007 2015-06-15 Since we have the y column which is actually Bitcoin Price, we need to aggregate that weekly using the aggregate function week_y&lt;-aggregate(y ~ week, #refers to column for bitcoin data=ch3_p1.1, FUN = mean #specifies that the mean function should be applied to the numeric column within each week ) You will notice that this creates a separate data frame. We will merge week_y with ch3_p1.1 ch3_p1.1&lt;-merge(ch3_p1.1, week_y, by = &quot;week&quot;, #ensures the merge aligns based on the week suffixes = c(&quot;&quot;,&quot;_weekly&quot;)) #adds _weekly to the column name to distinguish them from the original columns We will slightly do the same thing when aggregating by month, quarter and year. I will do the initial steps, but please do the succeeding steps on your own. 7.1.7.2 Aggregate by Month # Add a month column ch3_p1.1$month &lt;- format(ch3_p1.1$ds, &quot;%Y-%m&quot;) # Calculate monthly means month_y &lt;- aggregate(y ~ month, data = ch3_p1.1, FUN = mean) Do the next steps as well as inspection on your own. 7.1.7.3 Aggregate by Quarter This is different since we will use the paste0 and the format functions. The format function extracts the year from the date and extracts the quarter from the date. The paste0 combines the year and quarter without a space between them so that it results in which quarter of which year. ch3_p1.1$quarter &lt;- paste0(format(ch3_p1.1$ds, &quot;%Y&quot;), &quot; &quot;, quarters(ch3_p1.1$ds)) 7.1.7.4 Aggregate by Year ch3_p1.1$year&lt;-format(ch3_p1.1$ds, &quot;%Y&quot;) Can you aggregate the Bitcoin values quarterly and yearly on your own with inspection? 7.2 Panel Data We will use a package in R containing different datasets. if(!(&quot;wooldridge&quot; %in% installed.packages()[,&quot;Package&quot;])) install.packages(&quot;wooldridge&quot;) library(wooldridge) data(&quot;wagepan&quot;) Unlike importing CSV, Excel or RData, since the data is found in a package, we call for the data through loading the package then data(\"dataset_name\"). The dataset will appear in the environment. str(wagepan) ## &#39;data.frame&#39;: 4360 obs. of 44 variables: ## $ nr : int 13 13 13 13 13 13 13 13 17 17 ... ## $ year : int 1980 1981 1982 1983 1984 1985 1986 1987 1980 1981 ... ## $ agric : int 0 0 0 0 0 0 0 0 0 0 ... ## $ black : int 0 0 0 0 0 0 0 0 0 0 ... ## $ bus : int 1 0 1 1 0 1 1 1 0 0 ... ## $ construc: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ent : int 0 0 0 0 0 0 0 0 0 0 ... ## $ exper : int 1 2 3 4 5 6 7 8 4 5 ... ## $ fin : int 0 0 0 0 0 0 0 0 0 0 ... ## $ hisp : int 0 0 0 0 0 0 0 0 0 0 ... ## $ poorhlth: int 0 0 0 0 0 0 0 0 0 0 ... ## $ hours : int 2672 2320 2940 2960 3071 2864 2994 2640 2484 2804 ... ## $ manuf : int 0 0 0 0 0 0 0 0 0 0 ... ## $ married : int 0 0 0 0 0 0 0 0 0 0 ... ## $ min : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrthcen : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrtheast: int 1 1 1 1 1 1 1 1 1 1 ... ## $ occ1 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ2 : int 0 0 0 0 0 1 1 1 1 1 ... ## $ occ3 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ4 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ5 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ occ6 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ7 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ8 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ9 : int 1 1 1 1 0 0 0 0 0 0 ... ## $ per : int 0 1 0 0 1 0 0 0 0 0 ... ## $ pro : int 0 0 0 0 0 0 0 0 0 0 ... ## $ pub : int 0 0 0 0 0 0 0 0 0 0 ... ## $ rur : int 0 0 0 0 0 0 0 0 0 0 ... ## $ south : int 0 0 0 0 0 0 0 0 0 0 ... ## $ educ : int 14 14 14 14 14 14 14 14 13 13 ... ## $ tra : int 0 0 0 0 0 0 0 0 0 0 ... ## $ trad : int 0 0 0 0 0 0 0 0 1 1 ... ## $ union : int 0 1 0 0 0 0 0 0 0 0 ... ## $ lwage : num 1.2 1.85 1.34 1.43 1.57 ... ## $ d81 : int 0 1 0 0 0 0 0 0 0 1 ... ## $ d82 : int 0 0 1 0 0 0 0 0 0 0 ... ## $ d83 : int 0 0 0 1 0 0 0 0 0 0 ... ## $ d84 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ d85 : int 0 0 0 0 0 1 0 0 0 0 ... ## $ d86 : int 0 0 0 0 0 0 1 0 0 0 ... ## $ d87 : int 0 0 0 0 0 0 0 1 0 0 ... ## $ expersq : int 1 4 9 16 25 36 49 64 16 25 ... ## - attr(*, &quot;time.stamp&quot;)= chr &quot;25 Jun 2011 23:03&quot; In practice, it is best to leave the raw dataset untouched. Create a copy of the dataset and that is where you do modifications. ch3_p2&lt;-wagepan str(ch3_p2) ## &#39;data.frame&#39;: 4360 obs. of 44 variables: ## $ nr : int 13 13 13 13 13 13 13 13 17 17 ... ## $ year : int 1980 1981 1982 1983 1984 1985 1986 1987 1980 1981 ... ## $ agric : int 0 0 0 0 0 0 0 0 0 0 ... ## $ black : int 0 0 0 0 0 0 0 0 0 0 ... ## $ bus : int 1 0 1 1 0 1 1 1 0 0 ... ## $ construc: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ent : int 0 0 0 0 0 0 0 0 0 0 ... ## $ exper : int 1 2 3 4 5 6 7 8 4 5 ... ## $ fin : int 0 0 0 0 0 0 0 0 0 0 ... ## $ hisp : int 0 0 0 0 0 0 0 0 0 0 ... ## $ poorhlth: int 0 0 0 0 0 0 0 0 0 0 ... ## $ hours : int 2672 2320 2940 2960 3071 2864 2994 2640 2484 2804 ... ## $ manuf : int 0 0 0 0 0 0 0 0 0 0 ... ## $ married : int 0 0 0 0 0 0 0 0 0 0 ... ## $ min : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrthcen : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrtheast: int 1 1 1 1 1 1 1 1 1 1 ... ## $ occ1 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ2 : int 0 0 0 0 0 1 1 1 1 1 ... ## $ occ3 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ4 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ5 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ occ6 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ7 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ8 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ9 : int 1 1 1 1 0 0 0 0 0 0 ... ## $ per : int 0 1 0 0 1 0 0 0 0 0 ... ## $ pro : int 0 0 0 0 0 0 0 0 0 0 ... ## $ pub : int 0 0 0 0 0 0 0 0 0 0 ... ## $ rur : int 0 0 0 0 0 0 0 0 0 0 ... ## $ south : int 0 0 0 0 0 0 0 0 0 0 ... ## $ educ : int 14 14 14 14 14 14 14 14 13 13 ... ## $ tra : int 0 0 0 0 0 0 0 0 0 0 ... ## $ trad : int 0 0 0 0 0 0 0 0 1 1 ... ## $ union : int 0 1 0 0 0 0 0 0 0 0 ... ## $ lwage : num 1.2 1.85 1.34 1.43 1.57 ... ## $ d81 : int 0 1 0 0 0 0 0 0 0 1 ... ## $ d82 : int 0 0 1 0 0 0 0 0 0 0 ... ## $ d83 : int 0 0 0 1 0 0 0 0 0 0 ... ## $ d84 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ d85 : int 0 0 0 0 0 1 0 0 0 0 ... ## $ d86 : int 0 0 0 0 0 0 1 0 0 0 ... ## $ d87 : int 0 0 0 0 0 0 0 1 0 0 ... ## $ expersq : int 1 4 9 16 25 36 49 64 16 25 ... ## - attr(*, &quot;time.stamp&quot;)= chr &quot;25 Jun 2011 23:03&quot; 7.2.1 Sorting Panel Data We need to sort panel data so that they are ordered by individual (id), then time. This will help you when you do lags and differences. ch3_p2&lt;-ch3_p2 %&gt;% arrange(nr, year) head(ch3_p2) ## nr year agric black bus construc ent exper fin hisp poorhlth hours manuf married min nrthcen nrtheast occ1 occ2 occ3 occ4 occ5 occ6 occ7 ## 1 13 1980 0 0 1 0 0 1 0 0 0 2672 0 0 0 0 1 0 0 0 0 0 0 0 ## 2 13 1981 0 0 0 0 0 2 0 0 0 2320 0 0 0 0 1 0 0 0 0 0 0 0 ## 3 13 1982 0 0 1 0 0 3 0 0 0 2940 0 0 0 0 1 0 0 0 0 0 0 0 ## 4 13 1983 0 0 1 0 0 4 0 0 0 2960 0 0 0 0 1 0 0 0 0 0 0 0 ## 5 13 1984 0 0 0 0 0 5 0 0 0 3071 0 0 0 0 1 0 0 0 0 1 0 0 ## 6 13 1985 0 0 1 0 0 6 0 0 0 2864 0 0 0 0 1 0 1 0 0 0 0 0 ## occ8 occ9 per pro pub rur south educ tra trad union lwage d81 d82 d83 d84 d85 d86 d87 expersq ## 1 0 1 0 0 0 0 0 14 0 0 0 1.197540 0 0 0 0 0 0 0 1 ## 2 0 1 1 0 0 0 0 14 0 0 1 1.853060 1 0 0 0 0 0 0 4 ## 3 0 1 0 0 0 0 0 14 0 0 0 1.344462 0 1 0 0 0 0 0 9 ## 4 0 1 0 0 0 0 0 14 0 0 0 1.433213 0 0 1 0 0 0 0 16 ## 5 0 0 1 0 0 0 0 14 0 0 0 1.568125 0 0 0 1 0 0 0 25 ## 6 0 0 0 0 0 0 0 14 0 0 0 1.699891 0 0 0 0 1 0 0 36 7.2.2 Checking Panel Balance When using panel data, checking for a balanced panel is necessary to know if every individual is observed every time period. An unbalanced panel means some individuals are missing years. This matters because many econometric assumptions rely on balance; such as selection bias in the sense that when you do not detect imbalance, you might miss events like firms exiting the market or respondents dropping out. table(table(ch3_p2$nr)) ## ## 8 ## 545 From the result, we know that each of the 545 individuals were observed 8 times. For unbalanced panel, you will see an output with multiple numbers as these indicate the missing periods and individuals. The table(table(id)) tells you whether each individual has the same amount of time in the panel. 7.2.3 Creating Lagged Variables We know that economic processes do not happen simultaneously, that is why it is important to use lags. Lags enforce causality, not correlation. In panel data, lags are within-individual; So, the question you are trying to answer here is: “How did this individual’s past outcome affect this person’s current outcome?” When using the Fixed Effects which rely on within-unit variation over time, lag adjustments are needed because without them, fixed effects would not work. ch3_p2&lt;-ch3_p2 %&gt;% group_by(nr) %&gt;% mutate(lwage_lag = lag(lwage)) head(ch3_p2) ## # A tibble: 6 × 45 ## # Groups: nr [1] ## nr year agric black bus construc ent exper fin hisp poorhlth hours manuf married min nrthcen nrtheast occ1 occ2 occ3 occ4 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 13 1980 0 0 1 0 0 1 0 0 0 2672 0 0 0 0 1 0 0 0 0 ## 2 13 1981 0 0 0 0 0 2 0 0 0 2320 0 0 0 0 1 0 0 0 0 ## 3 13 1982 0 0 1 0 0 3 0 0 0 2940 0 0 0 0 1 0 0 0 0 ## 4 13 1983 0 0 1 0 0 4 0 0 0 2960 0 0 0 0 1 0 0 0 0 ## 5 13 1984 0 0 0 0 0 5 0 0 0 3071 0 0 0 0 1 0 0 0 0 ## 6 13 1985 0 0 1 0 0 6 0 0 0 2864 0 0 0 0 1 0 1 0 0 ## # ℹ 24 more variables: occ5 &lt;int&gt;, occ6 &lt;int&gt;, occ7 &lt;int&gt;, occ8 &lt;int&gt;, occ9 &lt;int&gt;, per &lt;int&gt;, pro &lt;int&gt;, pub &lt;int&gt;, rur &lt;int&gt;, south &lt;int&gt;, ## # educ &lt;int&gt;, tra &lt;int&gt;, trad &lt;int&gt;, union &lt;int&gt;, lwage &lt;dbl&gt;, d81 &lt;int&gt;, d82 &lt;int&gt;, d83 &lt;int&gt;, d84 &lt;int&gt;, d85 &lt;int&gt;, d86 &lt;int&gt;, d87 &lt;int&gt;, ## # expersq &lt;int&gt;, lwage_lag &lt;dbl&gt; It is important to do group_by because each individual has their own time line and the lags stay within individuals. Therefore, what this does is treating each individual as separate time series. 7.2.4 Missing Data in Panels colSums(is.na(ch3_p2)) ## nr year agric black bus construc ent exper fin hisp poorhlth hours manuf married ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## min nrthcen nrtheast occ1 occ2 occ3 occ4 occ5 occ6 occ7 occ8 occ9 per pro ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## pub rur south educ tra trad union lwage d81 d82 d83 d84 d85 d86 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## d87 expersq lwage_lag ## 0 0 545 ch3_p2.1&lt;-ch3_p2 %&gt;% filter(!is.na(lwage_lag)) 7.2.5 Creating Growth Rates ch3_p2 &lt;- ch3_p2 %&gt;% group_by(nr) %&gt;% mutate( wg = lwage - lag(lwage) ) head(ch3_p2$wg, 10) #due to number of cols, chose the one we just created and specified 10 observations ## [1] NA 0.65551984 -0.50859833 0.08875167 0.13491178 0.13176584 -2.42015356 2.38945049 NA -0.15756428 What we did was create within-individual wage growth over time. Remember our discussion on lag? It will answer: “How much did this individual’s wage change from the previous period?” Furthermore, we are doing dynamic analysis here. We also note that the first observation per person has no lag. 7.3 Closing Quiz questions will be uploaded in Animospace. You have 15 minutes to answer. Clean the environment and free the memory AFTER the quiz. "],["visualizations-using-ggplot2.html", "8 Visualizations using ggplot2 8.1 Preliminaries 8.2 Pre-plotting Check 8.3 Visualizing Data using geom 8.4 Visualizing Time Series Data 8.5 Closing 8.6 Visualizations using Base R 8.7 Closing", " 8 Visualizations using ggplot2 For this lecture, we will be using ggplot2 package. Please make sure that you have it installed. The package works best with data in the ‘long’ format so it helps to modify the dataset to this format rather than a wide format. 8.1 Preliminaries 8.1.1 Load the dataset The dataset can be downloaded from the Modules. We will use Ch4PracticeA for this portion of the discussion. Unlike previous datasets that we loaded, we are now loading an Excel file. We will need the readxl package for this. Also, it is important to check if there are additional sheets and which sheet you will need. There are actually two sheets in the Excel file, but we will only use the first sheet named base. rm(list=ls()) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 1633868 87.3 2599520 138.9 2599520 138.9 ## Vcells 3704821 28.3 8388608 64.0 8388604 64.0 library(readxl) ch4_p1 &lt;- read_excel(&quot;Ch4PracticeA.xlsx&quot;, sheet = &quot;base&quot;) I will not delve deeply in the description. Please read up on it. The description can be found in the last sheet of the Excel file. Next, we load the following package: tidyverse and ggplot2. library(tidyverse) ## ── Attaching core tidyverse packages ────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ── ## ✔ forcats 1.0.1 ✔ readr 2.1.6 ## ✔ ggplot2 4.0.1 ✔ tibble 3.3.0 ## ✔ purrr 1.2.0 ## ── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(ggplot2) 8.2 Pre-plotting Check In some cases, ggplot2 does not run. This can be brought by package mismatch, so, we need to double-check that everything is working properly. user &lt;- file.path(Sys.getenv(&quot;USERPROFILE&quot;), &quot;R&quot;, &quot;win-library&quot;, &quot;4.5&quot;) dir.create(user, recursive = TRUE, showWarnings = FALSE) .libPaths(c(user, .libPaths())) ok &lt;- tryCatch({ library(ggplot2) ggplot(data.frame(x=1:5, y=rnorm(5)), aes(x,y)) + geom_point() TRUE }, error = function(e) FALSE) if (!ok) { install.packages(&quot;rlang&quot;, lib = user_lib) ok &lt;- tryCatch({ library(ggplot2) ggplot(data.frame(x=1:5, y=rnorm(5)), aes(x,y)) + geom_point() TRUE }, error = function(e) FALSE) } if (!ok) plot(1:5, rnorm(5)) If it is still not working, please refer to Visualization using Base R 8.2.1 Template There is a basic template that can be used for different types of plots: &lt;DATA&gt; %&gt;% ggplot(aes(&lt;MAPPINGS&gt;))+ &lt;GEOM_FUNCTION&gt;() ggplot is a function that expects a data frame to be the first argument. This allows for us to change from specifying the data = argument within the ggplot function and instead pipe the data into the function. Use the ggplot() function… ch4_p1 %&gt;% ggplot() Now, we define the mapping (using the aesthetic (aes) function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x/y positions or characteristics such as size, shape, color, etc. ch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures)) The next step is to add geom which will make the graphical representations of the data. These include: geom_point() for scatter plots, dot plots, etc. geom_boxplot() for boxplots geom_line() for trend lines, time series, etc. geom_bar() for bar plots and pie charts 8.3 Visualizing Data using geom 8.3.1 Scatterplots Let us use the geom_point() first then we will do the others after. Also, scatterplots are useful when you want to display the relationship between two continuous variables. Can you give me an example of when to use scatterplots? ch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures)) + geom_point() This visualization is so unclear; this is due to the number of observations being more than 9,000. Let’s just use the first 500 rows as this is for our practice and for visualization purposes. fch4_p1 &lt;- head(ch4_p1, 500) View(fch4_p1) This is more manageable; let’s try the scatterplot again, this time using the fch4_p1 dataset. fch4_p1%&gt;% ggplot(aes(x=poverty_index, y=health_expenditures)) + geom_point() This is more visible; There are some points that overlap with each other. Let us incorporate some strategies to try and ensure that there will be no overplotting issues. The first strategy is changing the transparency of the points. To control the transparency of points, we add the alpha argument. The range of transparency is from 0 to 1, with lower values corresponding to more transparency. The default value is 1. Let’s try to change the alpha to 0.5. fch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures)) + geom_point(alpha=0.5) Some of the points are gray while the others are much darker, then we can see (slightly) the difference. Another method that we can do is jittering the points on the plot to see the locations where there are overplotting points. Jittering adds randomness into the position of the points. To do this, we add geom_jitter() rather than geom_point(). Also, we need to edit the width and height. You can experiment but if you want less spread, pick values between 0.1 and 0.4. fch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures)) + geom_jitter(alpha = 0.5, width= 0.3, height= 0.3) Let us add color to geom_jitter() fch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures)) + geom_jitter(alpha = 0.5, color = &quot;darkgreen&quot;, width= 0.3, height= 0.3) If you want to have different colors depending on a certain variable, we need to use a vector as an input in the argument color. Here though, we map features of the data to a certain color. When we map a variable in our data to the color of the points, ggplot2 will provide a different color corresponding to the different values of the variable. We will continue to specify the value of alpha, width, and height outside of the aes function because we are using the same value for every point. fch4_p1$enrolled&lt;-as.factor(fch4_p1$enrolled) fch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures))+ geom_jitter(aes(color=enrolled), alpha=0.5, width=0.3, height=0.3) We can add a regression line to the plot. The line helps us summarize and predict the relationship between our two variables. To add, it is geom_smooth(method=\"lm\",...) you can edit the design and you can remove the confidence interval (gray area) with placing inside the parenthesis se=FALSE. fch4_p1$enrolled&lt;-as.factor(fch4_p1$enrolled) fch4_p1 %&gt;% ggplot(aes(x=poverty_index, y=health_expenditures))+ geom_jitter(aes(color=enrolled), alpha=0.5, width=0.3, height=0.3)+ geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;, linewidth = 1) ## `geom_smooth()` using formula = &#39;y ~ x&#39; 8.3.2 Boxplots Here is how to make a box plot that is useful when summarizing the distribution of a continuous variable, highlighting the median, quartiles, and potential outliers. To interpret a boxplot, take note of the following things: Horizontal Line in the Box: this is the median wherein it represents the 50% of the data. The Box Itself (Q1 to Q3): The box represents the middle 50% of the data, at the bottom of the box, that is the Q1 (25th percentile) while the top of box is the Q3 (75th percentile). A taller box means more variability is present in the middle of the data Whiskers extend from the box to represent the range of the data excluding outliers so it usually end at the smallest and largest data points. It shows the spread of data outside the middle 50%. Longer whiskers point to greater spread in that direction Outliers are points outside the whiskers. 8.3.2.1 Skewness This describes the asymmetry of a data distribution, it can be right-skewed or left-skewed. Boxplots are a great way to visualize skewness. Right-skewed The right tail is longer, meaning, median is closer to the bottom and has a longer top whisker. Most data values are smaller with few large values ex. income, price Left-skewed The left tail is longer, meaning, median is closer to the top and has a longer bottom whisker. Most data values are large with few small values test scores *The labs argument is to add labels in the plot. fch4_p1 %&gt;% ggplot(aes(x = as.factor(treatment_locality), y = health_expenditures)) + geom_boxplot(fill = &quot;green&quot;) + labs(title = &quot;Box Plot: Health Expenditures by Treatment Locality&quot;, x = &quot;Treatment Locality&quot;, y = &quot;Health Expenditures&quot;) + theme_minimal() You can also add some points in the box plot by adding geom_jitter fch4_p1 %&gt;% ggplot(aes(x = as.factor(treatment_locality), y = health_expenditures)) + geom_boxplot(fill=&quot;green&quot;) + geom_jitter(alpha = 0.5, color = &quot;tomato&quot;, width = 0.2, height = 0.2) + labs(title = &quot;Box Plot: Health Expenditures by Treatment Locality&quot;, x = &quot;Treatment Locality&quot;, y = &quot;Health Expenditures&quot;) + theme_minimal() 8.3.3 Bar plots Barplots are also useful for visualizing categorical data. By default, geom_bar accepts a variable for x, and plots the number of instances each value of x (in this case, treatment_locality) appears in the dataset. fch4_p1 %&gt;% ggplot(aes(x = as.factor(treatment_locality))) + geom_bar(fill = &quot;lightgreen&quot;) + labs(title = &quot;Bar Plot: Count of Localities by Treatment Locality&quot;, x = &quot;Treatment Locality&quot;, y = &quot;Count&quot;) + theme_minimal() Let us change the fill to be locality_identifier. Note, we will have a lot of colors here but this is done for visualization purposes and practice. fch4_p1 %&gt;% ggplot(aes(x = as.factor(treatment_locality), fill = as.factor(locality_identifier))) + geom_bar() + labs(title = &quot;Bar Plot: Count of Localities by Treatment Locality and Locality&quot;, x = &quot;Treatment Locality&quot;, y = &quot;Count&quot;, fill = &quot;Locality&quot;) + theme_minimal() This creates a stacked bar chart. These are generally more difficult to read than side-by-side bars. We can separate the portions of the stacked bar that correspond to each village and put them side-by-side by using the position argument for geom_bar() and setting it to “dodge”. fch4_p1 %&gt;% ggplot(aes(x = as.factor(treatment_locality), fill = as.factor(locality_identifier))) + geom_bar(position = &quot;dodge&quot;) + labs(title = &quot;Bar Plot: Count of Localities by Treatment Locality and Locality&quot;, x = &quot;Treatment Locality&quot;, y = &quot;Count&quot;, fill = &quot;Locality&quot;) + theme_minimal() What if you want to visualize a numeric value for each category? geom_bar() only visualizes the number of observations for a categorical x-variable. We use geom_col() which allows us to visualize numeric values. I will create 4 groups for locality_group so that we have better-looking bars. fch4_p1 &lt;- fch4_p1 %&gt;% mutate(locality_group = cut(locality_identifier, breaks = c(20, 40, 60, 80, 100), labels = c(&quot;20-40&quot;, &quot;40-60&quot;, &quot;60-80&quot;, &quot;80-100&quot;), include.lowest = TRUE)) table(fch4_p1$locality_group) ## ## 20-40 40-60 60-80 80-100 ## 197 42 66 51 fch4_p1 %&gt;% ggplot(aes(x = as.factor(locality_group), y=health_expenditures, fill = as.factor(locality_group))) + geom_col(position = &quot;dodge&quot;) + labs(title = &quot;Bar Plot: Count of Localities by Treatment Locality and Locality&quot;, x = &quot;Locality Group&quot;, y = &quot;Health Expenditures&quot;, fill = &quot;Locality&quot;) + theme_minimal() Want to have height arrangement? Since locality_group appears multiple times, we have to calculate for the mean expenditures per locality_group or total expenditures per locality_group using the .fun=mean or .fun=sum then, from largest to smallest height, we say .desc = TRUE. The fct_reorder is used because we have the calculations per group and the bars are reordered based on the calculations. fch4_p1 %&gt;% mutate(locality_group = fct_reorder(locality_group, health_expenditures, .fun = sum, .desc = TRUE)) %&gt;% ggplot(aes(x = locality_group, y = health_expenditures, fill = locality_group)) + geom_col() + labs( title = &quot;Health Expenditures by Locality Group&quot;, x = &quot;Locality Group&quot;, y = &quot;Health Expenditures&quot;, fill = &quot;Locality Group&quot; ) + theme_minimal() # + coord_flip() if names are too long 8.3.4 Faceting ggplot2 has a special technique called faceting that allows the user to split one plot into multiple plots based on a factor included in the dataset. fch4_p1 %&gt;% ggplot(aes(x = poverty_index, y = health_expenditures)) + geom_point(alpha = 0.6, color = &quot;darkblue&quot;) + facet_wrap(~ locality_identifier, ncol = 4) + labs(title = &quot;Faceted Scatter Plot by Locality Identifier&quot;, x = &quot;Poverty Index&quot;, y = &quot;Health Expenditures&quot;) + theme_minimal() It doesn’t look that nice; let’s use the locality_group we created before. fch4_p1 %&gt;% ggplot(aes(x = poverty_index, y = health_expenditures)) + geom_point(alpha = 0.6, color = &quot;darkgreen&quot;) + facet_wrap(~ locality_group, ncol = 2) + labs(title = &quot;Faceted Scatter Plot by Locality Identifier&quot;, x = &quot;Poverty Index&quot;, y = &quot;Health Expenditures&quot;) + theme_minimal() 8.3.5 Pie Chart Pie charts are used to illustrate proportions or parts of a whole (limited to a small number of categories). Before we do the pie chart, we need to count how many observations there are in the variable we want to analyze. treatment_counts &lt;- fch4_p1 %&gt;% count(treatment_locality) ggplot(treatment_counts, aes(x = &quot;&quot;, y = n, fill = as.factor(treatment_locality))) + geom_bar(stat = &quot;identity&quot;, width = 1) + coord_polar(theta = &quot;y&quot;) + #this makes it a pie chart labs(title = &quot;Pie Chart: Proportion of Treatment Localities&quot;, fill = &quot;Treatment Locality&quot;) + theme_void() #another way to have a nice background If you want to put labels to each slice and let’s say you want the percentage for it, this is the code: treatment_counts &lt;- fch4_p1 %&gt;% count(treatment_locality) %&gt;% #for count mutate(percentage = n / sum(n) * 100, #calculate percentage label = paste0(treatment_locality, &quot;\\n&quot;, round(percentage, 1), &quot;%&quot;)) #add label for percentage ggplot(treatment_counts, aes(x = &quot;&quot;, y = n, fill = as.factor(treatment_locality))) + geom_bar(stat = &quot;identity&quot;, width = 1) + coord_polar(theta = &quot;y&quot;) + geom_text(aes(label = label), position = position_stack(vjust = 0.5), size = 4) + labs(title = &quot;Pie Chart: Proportion of Treatment Localities&quot;, fill = &quot;Treatment Locality&quot;) + theme_void() 8.3.6 Histogram Though it looks similar to a bar plot, a histogram is different since it displays the distribution of a continuous variable. It groups the data into intervals called bins and shows the frequency of data points within each bin. fch4_p1 %&gt;% ggplot(aes(x=poverty_index))+ geom_histogram(binwidth = 5, fill=&quot;green&quot;, color=&quot;black&quot;)+ theme_minimal() Here is a cheat sheet for ggplot2 from the ones who developed the package: ggplot2 Cheat Sheet 8.4 Visualizing Time Series Data When visualizing time series data, it is important to ensure that the time variable is formatted as Date. For this portion of the lecture, we use Ch4PracticeB.xlsx which is found in the Modules. Make sure to clean the environment, load the file and rename the columns since they are quite long. I will not show the codes for this portion anymore as I am sure you already know how. ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3411426 182.2 6563742 350.6 6563742 350.6 ## Vcells 6773129 51.7 12255594 93.6 10146323 77.5 ## # A tibble: 6 × 12 ## year nominal_gdp_current nominal_gdp_constant gdp_growth_current gdp_growth_constant total_debt debt_to_gdp interest_payments ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1986 692852 4298952 0.065 0.035 528347 0.783 21612 ## 2 1987 777283 4486464 0.122 0.044 566447 0.749 36905 ## 3 1988 910280 4786920 0.171 0.067 580682 0.656 45865 ## 4 1989 1054529 5082939 0.158 0.062 605106 0.59 54714 ## 5 1990 1227882 5239629 0.164 0.031 701129 0.587 71114 ## 6 1991 1422958 5216764 0.159 -0.004 768469 0.556 74922 ## # ℹ 4 more variables: amortization_payments &lt;dbl&gt;, phil_us_exchange_rate &lt;dbl&gt;, inflation &lt;dbl&gt;, fdi_net &lt;dbl&gt; Ensure the time variable is formatted as Date I will not show the code for this since this has been done in previous lectures. Template To make a time series visualization, this is the template: ggplot(data, aes(x = time_variable, y = value_variable)) + geom_line(color = &quot;blue&quot;) + #adds a trend line labs(title = &quot;Time Series Plot&quot;, x = &quot;Time&quot;, y = &quot;Value&quot;) + theme_minimal() Time Series Plot You might wonder why mine does not have a warning. Usually, there will be warnings that will come out. To remove it, simply add inside the {r}, warning=FALSE like: {r,warning=FALSE} options(scipen=999) #not scientific notation ch4_p2 %&gt;% ggplot(aes(x=year, y=nominal_gdp_current))+ geom_line(color=&quot;darkgreen&quot;)+ labs(title = &quot;Time Series Plot of Nominal GDP (Current)&quot;, x = &quot;Year&quot;, y = &quot;Nominal GDP (Current)&quot;) + theme_minimal() We can add points for clarity and change size of line to be thicker. options(scipen=999) ch4_p2 %&gt;% ggplot(aes(x=year, y=nominal_gdp_current))+ geom_line(color=&quot;pink&quot;, size=1)+ geom_point(color= &quot;purple&quot;)+ labs(title = &quot;Time Series Plot of Nominal GDP (Current)&quot;, x = &quot;Year&quot;, y = &quot;Nominal GDP (Current)&quot;) 8.5 Closing Quiz will be done for 15 minutes Clean the environment BEFORE the quiz. You will have a different dataset for the quiz. 8.6 Visualizations using Base R library(readxl) ch4_p1 &lt;- read_excel(&quot;Ch4PracticeA.xlsx&quot;, sheet = &quot;base&quot;) fch4_p1 &lt;- head(ch4_p1, 500) 8.6.1 Scatterplots plot(fch4_p1$poverty_index, fch4_p1$health_expenditures, xlab= &quot;Poverty Index&quot;, ylab= &quot;Health Expenditures&quot;, main=&quot;Scatterplot of Poverty Index vs Health Expenditures&quot;) Transparency In ggplot2, we use alpha but in Base R, we use rgb() plot(fch4_p1$poverty_index, fch4_p1$health_expenditures, col = rgb(0,0,0,0.5), pch=16, xlab= &quot;Poverty Index&quot;, ylab= &quot;Health Expenditures&quot;, main=&quot;Scatterplot of Poverty Index vs Health Expenditures&quot;) rgb for black is r=0, g=0, b=0 then the last is alpha 50% transparency. pch = 16 is solid filled circle, if it is 1, it is a hollow circle. Jitter plot(jitter(fch4_p1$poverty_index, amount = 0.3), jitter(fch4_p1$health_expenditures, amount=0.3), col=rgb(0,0.5,0, 0.5), pch=16, xlab= &quot;Poverty Index&quot;, ylab= &quot;Health Expenditures&quot;, main=&quot;Scatterplot of Poverty Index vs Health Expenditures&quot;) The amount is 0.3 which is the width and height equivalent of the jitter using ggplot2. We changed the color to green so g=0.5. Color by group (aes(color=enrolled)) colors&lt;-as.factor(fch4_p1$enrolled) plot(jitter(fch4_p1$poverty_index, amount = 0.3), jitter(fch4_p1$health_expenditures, amount=0.3), col= colors, pch=16, xlab= &quot;Poverty Index&quot;, ylab= &quot;Health Expenditures&quot;, main=&quot;Scatterplot of Poverty Index vs Health Expenditures&quot;) legend(&quot;topright&quot;, legend = levels(colors), col=1:length(levels(colors)), pch=16, title = &quot;Enrolled&quot;) We need to convert enrolled into categorical variable so that each value becomes a group. Base R automatically decides on the colors to each factor. In the legend, we manually tell R to provide it, and we set legend = levels(colors), as factor levels being their legend, col=1:length(levels(colors)) assigns legend colors then pch=16 for matching the plot symbols. Adding Regression Line You can add a regression line by adding abline(lm(y~x),...) colors&lt;-as.factor(fch4_p1$enrolled) plot(jitter(fch4_p1$poverty_index, amount = 0.3), jitter(fch4_p1$health_expenditures, amount=0.3), abline(lm(fch4_p1$health_expenditures ~ fch4_p1$poverty_index), col = &quot;red&quot;, lwd=2), col= colors, pch=16, xlab= &quot;Poverty Index&quot;, ylab= &quot;Health Expenditures&quot;, main=&quot;Scatterplot of Poverty Index vs Health Expenditures&quot;) legend(&quot;topright&quot;, legend = levels(colors), col=1:length(levels(colors)), pch=16, title = &quot;Enrolled&quot;) 8.6.2 Boxplots boxplot(health_expenditures ~ as.factor(treatment_locality), data=fch4_p1) If you want to change color, just add col = Adding jittered points boxplot(health_expenditures ~ as.factor(treatment_locality), data=fch4_p1, col=&quot;green&quot;, outline=FALSE) stripchart(health_expenditures ~ as.factor(treatment_locality), data=fch4_p1, vertical = TRUE, method = &quot;jitter&quot;, jitter = 0.2, pch=16, col = rgb(1,0.2,0.2,0.5), #similar to tomato color with transparency add = TRUE) We need to draw the boxplot before we add the jitter. outline = FALSE prevents double-plotting, stripchart() overlays the individual observations on the boxplot with jittering to avoid overlap, vertical = TRUE aligns points with the boxplots. 8.6.3 Bar Plots counts&lt;-table(fch4_p1$treatment_locality) barplot(counts, col=&quot;green&quot;) We need to count the values while barplot visualizes the counts Stacked Bar Plots counts_matrix &lt;- with(fch4_p1, table(treatment_locality, locality_identifier)) In the stacked bar plots, rows are the treatment_locality while columns are locality_identifier barplot(t(counts_matrix), col = rainbow(ncol(counts_matrix)), #color per row legend=TRUE) Side-by-Side Bars barplot(t(counts_matrix), beside = TRUE, # side-by-side col = rainbow(ncol(counts_matrix)), legend.text = TRUE) Reordering bars/when specified numeric value Unlike ggplot2, in base R, we need to calculate first. fch4_p1 &lt;- fch4_p1 %&gt;% mutate(locality_group = cut(locality_identifier, breaks = c(20, 40, 60, 80, 100), labels = c(&quot;20-40&quot;, &quot;40-60&quot;, &quot;60-80&quot;, &quot;80-100&quot;), include.lowest = TRUE)) table(fch4_p1$locality_group) ## ## 20-40 40-60 60-80 80-100 ## 197 42 66 51 agg &lt;- aggregate(health_expenditures ~ locality_group, data = fch4_p1, sum) agg &lt;- agg[order(agg$health_expenditures, decreasing = TRUE), ] barplot( height = agg$health_expenditures, names.arg = agg$locality_group, col = rainbow(nrow(agg)), main = &quot;Health Expenditures by Locality Group&quot;, xlab = &quot;Locality Group&quot;, ylab = &quot;Health Expenditures&quot;, las = 2 # rotate axis labels for readability ) 8.6.4 Faceting par(mfrow = c(2, 2)) for (g in levels(fch4_p1$locality_group)) { subset_data &lt;- subset(fch4_p1, locality_group == g) plot(subset_data$poverty_index, subset_data$health_expenditures, main = paste(&quot;Locality Group:&quot;, g), xlab = &quot;Poverty Index&quot;, ylab = &quot;Health Expenditures&quot;, pch = 16, col = rgb(0, 0.5, 0, 0.6)) } par(mfrow = c(1, 1)) You will notice that unlike ggplot2, Base R skips the missing. To avoid this, you have to create a separate category for missing. par(mfrow=c(nrows, ncols)) splits the plotting area then we created a function that loops each locality_group to have a different plot. Then, we reset the plotting layout with par(mfrow=c(1,1)) for succeeding plots. 8.6.5 Pie Chart tcounts &lt;- table(fch4_p1$treatment_locality) pie(tcounts, col = rainbow(length(tcounts)), main = &quot;Pie Chart: Proportion of Treatment Localities&quot;) Again, table() counts instances per category, while rainbow assigns a color to each category Adding Percentages per slice pslice &lt;- round(100 * tcounts / sum(tcounts), 1) #We create labels that includes the name of slice with the percent of each slice labels &lt;- paste(names(tcounts), &quot;\\n&quot;, pslice, &quot;%&quot;, sep=&quot;&quot;) pie(tcounts, labels = labels, col = rainbow(length(tcounts)), main = &quot;Pie Chart: Proportion of Treatment Localities&quot;) 8.6.6 Histogram hist(fch4_p1$poverty_index, col = &quot;green&quot;, border = &quot;black&quot;, xlab = &quot;Poverty Index&quot;, main = &quot;Histogram of Poverty Index&quot;) R automatically chooses breaks. 8.6.7 Time Series options(scipen=999) plot(ch4_p2$year, ch4_p2$nominal_gdp_current, type = &quot;l&quot;, col = &quot;darkgreen&quot;, xlab = &quot;Year&quot;, ylab = &quot;Nominal GDP (Current)&quot;, main = &quot;Time Series Plot of Nominal GDP (Current)&quot;) To make the line, the type is small letter L, not 1. To add points: options(scipen=999) plot(ch4_p2$year, ch4_p2$nominal_gdp_current, type = &quot;l&quot;, col = &quot;pink&quot;, lwd = 2, xlab = &quot;Year&quot;, ylab = &quot;Nominal GDP (Current)&quot;, main = &quot;Time Series Plot of Nominal GDP (Current)&quot;) points(ch4_p2$year, ch4_p2$nominal_gdp_current, col = &quot;purple&quot;, pch = 16) 8.7 Closing Quiz will be done for 15 minutes Clean the environment BEFORE the quiz. You will have a different dataset for the quiz. "],["advanced-visualizations.html", "9 Advanced Visualizations 9.1 Preliminaries 9.2 Animated Visualizations 9.3 Animated Time Series 9.4 Animated Faceted Time Series 9.5 Maps 9.6 Static Maps 9.7 Philippine Regional Map 9.8 Animated Map 9.9 Practical: Advanced Visualizations", " 9 Advanced Visualizations 9.1 Preliminaries 9.1.1 Install Packages For this lecture, you need to install a lot of packages. Please do this before our lecture as it will take a long time to install them. Furthermore, there might be issues in installing, such as needing to install other packages. Please let the professor know if you encounter any issues. # Install necessary packages if (!require(gganimate)) install.packages(&quot;gganimate&quot;) ## Loading required package: gganimate if (!require(ggplot2)) install.packages(&quot;ggplot2&quot;) if (!require(dplyr)) install.packages(&quot;dplyr&quot;) if (!require(sf)) install.packages(&quot;sf&quot;) ## Loading required package: sf ## Linking to GEOS 3.13.1, GDAL 3.11.4, PROJ 9.7.0; sf_use_s2() is TRUE if (!require(rnaturalearth)) install.packages(&quot;rnaturalearth&quot;) ## Loading required package: rnaturalearth if (!require(readr)) install.packages(&quot;readr&quot;) if (!require(tidyr)) install.packages(&quot;tidyr&quot;) if (!require(gifski)) install.packages(&quot;gifski&quot;) ## Loading required package: gifski if (!require(WDI)) install.packages(&quot;WDI&quot;) ## Loading required package: WDI if (!require(leaflet)) install.packages(&quot;leaflet&quot;) ## Loading required package: leaflet if (!require(rnaturalearthdata)) install.packages(&quot;rnaturalearthdata&quot;) ## Loading required package: rnaturalearthdata ## ## Attaching package: &#39;rnaturalearthdata&#39; ## The following object is masked from &#39;package:rnaturalearth&#39;: ## ## countries110 #Load packages library(gganimate) library(ggplot2) library(dplyr) library(sf) library(rnaturalearth) library(rnaturalearthdata) library(readr) library(tidyr) library(gifski) library(WDI) library(leaflet) 9.2 Animated Visualizations gganimate includes animation to ggplot2; It adds some classes to the plot object in order to customise how it should change with time. transition_*() defines how the data should be spread out and how it relates to itself across time. view_*() defines how the positional scales should change along the animation. shadow_*() defines how data from other points in time should be presented in the given point in time. enter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation. ease_aes() defines how different aesthetics should be eased during transitions For this lecture, we will use the quotas dataset and fetch some World Bank Development Indicators from the WDI package. 9.2.1 Animated Bar Chart At the start, you need to do the same steps as that of when doing the visualizations without animations. rm(list = ls()) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3628675 193.8 6563742 350.6 6563742 350.6 ## Vcells 7241908 55.3 14786712 112.9 11822712 90.3 # Load the dataset quotas &lt;- read.csv(&quot;quotas.csv&quot;) ch5.1&lt;-quotas %&gt;% ggplot(aes(x=factor(AC_type_noST)))+ geom_bar(fill=&quot;darkgreen&quot;, color=&quot;black&quot;)+ labs(title = &quot;Animated Bar Chart: Assembly Constituencies&quot;, x=&quot;Reservation Status&quot;, y=&quot;Count&quot;)+ theme_minimal()+ transition_states(AC_type_noST, transition_length = 2, state_length = 1) The transition_states animates transitions between different categorical states. The AC_type_noST is the categorical variable that defines different animation states. The transition_length controls how long the transition between states lasts, measured in animation frames. While the state_length defines how long each state remains static before transitioning to the next one. This is very important; it is different for Quarto where the gif is automatically rendered; however, later, we will find out how to save in Quarto. anim_file &lt;- &quot;bar_chart.gif&quot; animate(ch5.1, duration = 4, fps = 10, renderer = gifski_renderer(anim_file), preview = TRUE) # Preview the animation before rendering # Save animation as a GIF knitr::include_graphics(anim_file) The animate function generates the animation of the ggplot object ch5.1. duration = 4: Specifies that the animation should run for 4 seconds in total. fps = 10: Defines the frame rate, meaning the animation will show 10 frames per second. renderer = gifski_renderer(anim_file): Uses the gifski_renderer to save the animation as a GIF file named bar_chart.gif. preview = TRUE: Allows you to view the animation immediately in the RStudio Viewer before saving it as a file. 9.2.2 Animated Scatter Plot ch5.2&lt;-quotas %&gt;% ggplot(aes(x=Plit71, y=P_W71))+ geom_point(aes(color=factor(AC_type_noST)))+ labs(title=&quot;Animated Scatter Plot: Literacy vs. Employment&quot;, x=&quot;Literacy Rate (1971)&quot;, y=&quot;Employment Rate (1971)&quot;, color=&quot;Reservation Status&quot;)+ theme_minimal()+ transition_reveal(Plit71) Here, the transition_reveal animates the points to be revealed over literacy rates anim_file2&lt;-&quot;scatter_plot.gif&quot; animate(ch5.2, duration=20, fps=10, renderer=gifski_renderer(anim_file2), preview=TRUE) knitr::include_graphics(anim_file2) To slow down the animation, increase the duration and decrease fps. 9.2.3 Animated Faceted Scatter Plot 9.2.3.1 Fetching WDI Data For this portion, we will make use of the WDI database. To search which indicator you wish to work with, type WDIsearch(\"keyword\") ch5&lt;-WDI( country = c(&quot;USA&quot;,&quot;CHN&quot;, &quot;IND&quot;, &quot;BRA&quot;,&quot;NLD&quot;, &quot;JPN&quot;), indicator = c(&quot;NY.GDP.PCAP.CD&quot;, &quot;SP.DYN.LE00.IN&quot;), start = 2000, end = 2020, extra = TRUE ) This code chunk pulls data from the World Bank WDI database of 6 countries and two indicators (GDP per capita (current US$) and Life Expectancy at Birth (years). It fetches data from 2000 to 2020 and includes extra metadata such as region names and income levels. #Cleaning the dataset ch5 &lt;- ch5 %&gt;% rename(GDPpc = NY.GDP.PCAP.CD, Life_Exp = SP.DYN.LE00.IN) ch5&lt;-ch5 %&gt;% filter(!is.na(GDPpc), !is.na(Life_Exp)) head(ch5) ## country iso2c iso3c year status lastupdated GDPpc Life_Exp region capital longitude latitude income ## 1 Brazil BR BRA 2000 2025-12-19 3766.548 69.584 Latin America &amp; Caribbean Brasilia -47.9292 -15.7801 Upper middle income ## 2 Brazil BR BRA 2001 2025-12-19 3176.290 69.980 Latin America &amp; Caribbean Brasilia -47.9292 -15.7801 Upper middle income ## 3 Brazil BR BRA 2002 2025-12-19 2855.940 70.396 Latin America &amp; Caribbean Brasilia -47.9292 -15.7801 Upper middle income ## 4 Brazil BR BRA 2003 2025-12-19 3090.607 70.884 Latin America &amp; Caribbean Brasilia -47.9292 -15.7801 Upper middle income ## 5 Brazil BR BRA 2004 2025-12-19 3663.823 71.361 Latin America &amp; Caribbean Brasilia -47.9292 -15.7801 Upper middle income ## 6 Brazil BR BRA 2005 2025-12-19 4827.782 71.832 Latin America &amp; Caribbean Brasilia -47.9292 -15.7801 Upper middle income ## lending ## 1 IBRD ## 2 IBRD ## 3 IBRD ## 4 IBRD ## 5 IBRD ## 6 IBRD ch5.3&lt;-ch5 %&gt;% ggplot(aes(x=GDPpc, y=Life_Exp))+ geom_point(aes(color=region), alpha=0.7, size=3)+ labs(title=&quot;Faceted Scatter Plot: GDP vs. Life Expectancy&quot;, subtitle = &quot;Year: 2000-2020&quot;, x=&quot;GDP per Capita (USD)&quot;, y=&quot;Life Expectancy (Years)&quot;, color=&quot;Region&quot;)+ theme_minimal()+ facet_wrap(~country, ncol=3)+ scale_x_log10()+ #log scale for better visualization transition_states(year, transition_length = 2, state_length = 1) There are additional things here like the size=3 which changes the size of points. the scale_x_log10() was added because it applies a logarithmic scale to the x-axis since GDP per capital values vary widely, and a log scale makes comparisons clearer. The transition_states has year since each frame would represent a different year. anim_file3&lt;-&quot;faceted_scatter_plot.gif&quot; animate(ch5.3, duration=10, fps=15, renderer=gifski_renderer(anim_file3), preview=TRUE) knitr::include_graphics(anim_file3) This does not really provide any information. Let us try visualizing in a different way. 9.3 Animated Time Series Let us just choose USA for this. ch5_1&lt;-ch5 %&gt;% filter(iso3c==&quot;USA&quot;) ch5.4&lt;-ch5_1 %&gt;% ggplot(aes(x=year, y=GDPpc))+ geom_line(color=&quot;green&quot;, size = 1.2)+ geom_point(color=&quot;purple&quot;, size=2)+ labs(title = &quot;US GDP per Capita Growth over Time&quot;, subtitle = &quot;Year:2000-2020&quot;, x=&quot;Year&quot;, y=&quot;GDP per Capita (Current US$)&quot;)+ theme_minimal()+ transition_reveal(year) anim_file4&lt;-&quot;us_timeseries.gif&quot; animate(ch5.4, duration = 10, fps = 15, renderer = gifski_renderer(anim_file4), preview = TRUE) knitr::include_graphics(anim_file4) 9.4 Animated Faceted Time Series ch5.5&lt;-ch5 %&gt;% ggplot(aes(x=year, y=GDPpc, group=country))+ geom_line(aes(color=country), size=1.2)+ labs(title = &quot;Faceted Time Series: GDP Growth Over Time&quot;, subtitle = &quot;Year: 2000-2020&quot;, x=&quot;Year&quot;, y=&quot;GDP (Current US$)&quot;, color=&quot;Country&quot;)+ theme_minimal()+ facet_wrap(~country, scales = &quot;free_y&quot;)+ #allows free-scaling in the y-axis transition_reveal(year) anim_file5&lt;-&quot;timeseries.gif&quot; animate(ch5.5, duration = 10, fps = 15, renderer = gifski_renderer(anim_file5), preview = TRUE) knitr::include_graphics(anim_file5) 9.4.1 Saving in Quarto For Data Presentation, you need to save interactive visualizations so that you can place them in your presentations. # Create an animated plot p &lt;- ggplot(DATA, aes(MAPPINGS)) + geom_function + transition_states(gear, transition_length = 2, state_length = 1) # Save as GIF anim_save(&quot;animation.gif&quot;, p) # Save as MP4 anim_save(&quot;animation.mp4&quot;, p) 9.5 Maps 9.5.1 Where to get shapefiles? The rnaturalearth provides some shapefiles you can use. A suggested site to find shapefiles of different countries: https://gadm.org/index.html . You can also locate shapefiles from the government sites. We will make use of the packages like WDI, rnaturalearth,sf, gganimate, and leaflet. Do note however, that gganimate and leaflet does not work for PDF, thus, it can only be used for your Data Story Presentation. 9.6 Static Maps 9.6.1 Fetching GDP Data from WDI rm(list=ls()) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3713096 198.4 6563742 350.6 6563742 350.6 ## Vcells 8103190 61.9 14786712 112.9 12422070 94.8 ch5_2&lt;-WDI(country = &quot;all&quot;, indicator = &quot;NY.GDP.MKTP.CD&quot;, start = 2000, end = 2022, extra=TRUE) #clean the dataset ch5_2&lt;-ch5_2 %&gt;% rename(gdp=NY.GDP.MKTP.CD, iso_a3=iso2c) %&gt;% drop_na(gdp) #dropping missing values We are retrieving GDP data for all countries from 2000 to 2022 and we are also renaming columns to match with map data found in the rnaturalearth. We also remove missing GDP values ch5map&lt;-ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) This fetches the world map with country boundaries in sf (simple features) format to visualize the GDP data. We fetch medium-scale country boundaries in spatial data format and the returnclass=\"sf\" ensures it can be used with ggplot2 #Merge wgdp&lt;-ch5map %&gt;% left_join(ch5_2, by=&quot;iso_a3&quot;) We need to match the GDP data with the corresponding country for visualization. You can opt to retrieve the world map to find out how to merge both. ggplot(data = wgdp) + geom_sf(aes(fill = gdp_md)) + scale_fill_viridis_c(option = &quot;plasma&quot;, trans = &quot;log&quot;, na.value = &quot;grey&quot;) + theme_minimal() + labs(title = &quot;GDP by Country&quot;, subtitle = &quot;Data from WDI&quot;, fill = &quot;GDP (log scale)&quot;) We use the merged map and GDP data and geom_sf(aes(fill=gdp_md)) filles countries based on GDP. The scale_fill_viridis_c uses “plasma” which is best used for maps. The log scale transformation is used to better differentiate large economies and small economies and grey fill for missing data. 9.6.1.1 Animated World Map for GDP Now we create an animated version of the map. You need to check that your time variable does not have any NA. It would be better to choose the years that are available consecutively so we will filter the data to only include from 2009-2019. unique(wgdp$gdp_year) ## [1] 2019 2014 2018 2017 2016 2013 2010 2009 2012 2006 2015 2003 2007 2011 # Filter for years 2009-2019 wgdp_filtered &lt;- wgdp %&gt;% filter(gdp_year %in% 2009:2019) ch5.6 &lt;- ggplot(data = wgdp_filtered) + geom_sf(aes(fill = gdp_md)) + scale_fill_viridis_c(option = &quot;plasma&quot;, trans = &quot;log&quot;, na.value = &quot;grey50&quot;) + theme_minimal() + labs(title = &quot;World GDP by Country: {closest_state}&quot;, subtitle = &quot;Data from World Development Indicators&quot;, fill = &quot;GDP (log scale)&quot;) + transition_states(gdp_year) + ease_aes(&#39;linear&#39;) anim_file6&lt;-&quot;worldgdp.gif&quot; animate(ch5.6, duration = 10, fps = 15, renderer = gifski_renderer(anim_file6), preview = TRUE) knitr::include_graphics(anim_file6) 9.7 Philippine Regional Map We will use Ch6.xlsx containing Regional GDP and use the Philippine Regions shapefile. rm(list=ls()) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3781354 202 6563742 350.6 6563742 350.6 ## Vcells 8510047 65 14786712 112.9 14767025 112.7 library(sf) layers&lt;-st_layers(&quot;PH_Adm1_Regions.shp&quot;) print(layers) ## Driver: ESRI Shapefile ## Available layers: ## layer_name geometry_type features fields crs_name ## 1 PH_Adm1_Regions.shp Polygon 17 7 WGS 84 / UTM zone 51N ## 2 Regions.shp Polygon 17 19 WGS 84 sp_df = sf::st_read( dsn= &#39;PH_Adm1_Regions.shp&#39;, layer=&quot;Regions.shp&quot;) ## Reading layer `Regions.shp&#39; from data source `C:\\Users\\jemma\\OneDrive\\Documents\\DLSU\\LBOMETR_Book\\PH_Adm1_Regions.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 17 features and 19 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 114.2779 ymin: 4.587294 xmax: 126.605 ymax: 21.12189 ## Geodetic CRS: WGS 84 The code loads the sf package then st_layers checks all available layers in the shapefile because some shapefiles contains multiple layers like administrative boundaries, water bodies, etc. so we display the available layers in the console. The st_read(dsn \"PH_Adm1_Regions.shp\") specifies the data source and the layer = \"Regions.shp\" specifies the layer name to read (the one we will use and need). Let us check if the shapefile was loaded correctly. print(sp_df) #check structure ## Simple feature collection with 17 features and 19 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 114.2779 ymin: 4.587294 xmax: 126.605 ymax: 21.12189 ## Geodetic CRS: WGS 84 ## First 10 features: ## psgc_code name corr_code geo_level city_class inc_class urb_rur pop_2015 pop_2020 status adm1_pcode ## 1 100000000 Region I (Ilocos Region) 10000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH01 ## 2 200000000 Region II (Cagayan Valley) 20000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH02 ## 3 300000000 Region III (Central Luzon) 30000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH03 ## 4 400000000 Region IV-A (CALABARZON) 40000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH04 ## 5 500000000 Region V (Bicol Region) 50000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH05 ## 6 600000000 Region VI (Western Visayas) 60000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH06 ## 7 700000000 Region VII (Central Visayas) 70000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH07 ## 8 800000000 Region VIII (Eastern Visayas) 80000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH08 ## 9 900000000 Region IX (Zamboanga Peninsula) 90000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH09 ## 10 1000000000 Region X (Northern Mindanao) 100000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH10 ## adm1_en adm1_alt adm0_pcode adm0_en date shape_len shape_area shape_sqkm ## 1 Region I (Ilocos Region) Ilocos Region PH Philippines (the) 2022-11-09 14.99505 1.043983 12307.35 ## 2 Region II (Cagayan Valley) Cagayan Valley PH Philippines (the) 2022-11-09 19.13905 2.241812 26387.73 ## 3 Region III (Central Luzon) Central Luzon PH Philippines (the) 2022-11-09 15.94956 1.793513 21304.16 ## 4 Region IV-A (Calabarzon) Calabarzon PH Philippines (the) 2022-11-09 27.62549 1.326720 15846.63 ## 5 Region V (Bicol Region) Bicol Region PH Philippines (the) 2022-11-09 44.92324 1.446324 17338.38 ## 6 Region VI (Western Visayas) Western Visayas PH Philippines (the) 2022-11-09 27.77415 1.657591 20047.63 ## 7 Region VII (Central Visayas) Central Visayas PH Philippines (the) 2022-11-09 29.11311 1.178431 14293.66 ## 8 Region VIII (Eastern Visayas) Eastern Visayas PH Philippines (the) 2022-11-09 42.02116 1.726804 20835.68 ## 9 Region IX (Zamboanga Peninsula) Zamboanga Peninsula PH Philippines (the) 2022-11-09 23.18144 1.196677 14596.05 ## 10 Region X (Northern Mindanao) Northern Mindanao PH Philippines (the) 2022-11-09 15.00295 1.435115 17489.29 ## geometry ## 1 MULTIPOLYGON (((120.9714 18... ## 2 MULTIPOLYGON (((121.9488 21... ## 3 MULTIPOLYGON (((122.2342 16... ## 4 MULTIPOLYGON (((122.3079 14... ## 5 MULTIPOLYGON (((122.9882 11... ## 6 MULTIPOLYGON (((121.4341 12... ## 7 MULTIPOLYGON (((124.093 11.... ## 8 MULTIPOLYGON (((124.3678 12... ## 9 MULTIPOLYGON (((123.4129 8.... ## 10 MULTIPOLYGON (((124.6987 9.... We then check available attributes and also check the region names so that we can merge the shapefile with our GDP data. colnames(sp_df) ## [1] &quot;psgc_code&quot; &quot;name&quot; &quot;corr_code&quot; &quot;geo_level&quot; &quot;city_class&quot; &quot;inc_class&quot; &quot;urb_rur&quot; &quot;pop_2015&quot; &quot;pop_2020&quot; &quot;status&quot; ## [11] &quot;adm1_pcode&quot; &quot;adm1_en&quot; &quot;adm1_alt&quot; &quot;adm0_pcode&quot; &quot;adm0_en&quot; &quot;date&quot; &quot;shape_len&quot; &quot;shape_area&quot; &quot;shape_sqkm&quot; &quot;geometry&quot; head(sp_df) ## Simple feature collection with 6 features and 19 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 119.7497 ymin: 9.444193 xmax: 124.4249 ymax: 21.12189 ## Geodetic CRS: WGS 84 ## psgc_code name corr_code geo_level city_class inc_class urb_rur pop_2015 pop_2020 status adm1_pcode ## 1 100000000 Region I (Ilocos Region) 10000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH01 ## 2 200000000 Region II (Cagayan Valley) 20000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH02 ## 3 300000000 Region III (Central Luzon) 30000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH03 ## 4 400000000 Region IV-A (CALABARZON) 40000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH04 ## 5 500000000 Region V (Bicol Region) 50000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH05 ## 6 600000000 Region VI (Western Visayas) 60000000 Reg &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; PH06 ## adm1_en adm1_alt adm0_pcode adm0_en date shape_len shape_area shape_sqkm ## 1 Region I (Ilocos Region) Ilocos Region PH Philippines (the) 2022-11-09 14.99505 1.043983 12307.35 ## 2 Region II (Cagayan Valley) Cagayan Valley PH Philippines (the) 2022-11-09 19.13905 2.241812 26387.73 ## 3 Region III (Central Luzon) Central Luzon PH Philippines (the) 2022-11-09 15.94956 1.793513 21304.16 ## 4 Region IV-A (Calabarzon) Calabarzon PH Philippines (the) 2022-11-09 27.62549 1.326720 15846.63 ## 5 Region V (Bicol Region) Bicol Region PH Philippines (the) 2022-11-09 44.92324 1.446324 17338.38 ## 6 Region VI (Western Visayas) Western Visayas PH Philippines (the) 2022-11-09 27.77415 1.657591 20047.63 ## geometry ## 1 MULTIPOLYGON (((120.9714 18... ## 2 MULTIPOLYGON (((121.9488 21... ## 3 MULTIPOLYGON (((122.2342 16... ## 4 MULTIPOLYGON (((122.3079 14... ## 5 MULTIPOLYGON (((122.9882 11... ## 6 MULTIPOLYGON (((121.4341 12... library(dplyr) unique(sp_df$name) ## [1] &quot;Region I (Ilocos Region)&quot; &quot;Region II (Cagayan Valley)&quot; ## [3] &quot;Region III (Central Luzon)&quot; &quot;Region IV-A (CALABARZON)&quot; ## [5] &quot;Region V (Bicol Region)&quot; &quot;Region VI (Western Visayas)&quot; ## [7] &quot;Region VII (Central Visayas)&quot; &quot;Region VIII (Eastern Visayas)&quot; ## [9] &quot;Region IX (Zamboanga Peninsula)&quot; &quot;Region X (Northern Mindanao)&quot; ## [11] &quot;Region XI (Davao Region)&quot; &quot;Region XII (SOCCSKSARGEN)&quot; ## [13] &quot;National Capital Region (NCR)&quot; &quot;Cordillera Administrative Region (CAR)&quot; ## [15] &quot;Region XIII (Caraga)&quot; &quot;MIMAROPA Region&quot; ## [17] &quot;Bangsamoro Autonomous Region In Muslim Mindanao (BARMM)&quot; sp_df &lt;- sp_df %&gt;% rename(region = name) Now, we load our Regional GDP package; library(readxl) rgdp&lt;-read_excel(&quot;Ch5PracticeB.xlsx&quot;, sheet = &quot;Sheet1&quot;) ## New names: ## • `` -&gt; `...1` head(rgdp) ## # A tibble: 6 × 26 ## ...1 region `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` `2008` `2009` `2010` `2011` `2012` `2013` `2014` `2015` `2016` `2017` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NCR Nationa… 2.42e9 2.48e9 2.51e9 2.62e9 2.84e9 2.99e9 3.16e9 3.37e9 3.52e9 3.52e9 3.75e9 3.83e9 4.07e9 4.34e9 4.58e9 4.87e9 5.22e9 5.51e9 ## 2 CAR Cordill… 1.44e8 1.49e8 1.56e8 1.64e8 1.73e8 1.76e8 1.83e8 1.96e8 2.03e8 2.08e8 2.20e8 2.21e8 2.22e8 2.37e8 2.49e8 2.60e8 2.67e8 2.92e8 ## 3 I Ilocos … 2.40e8 2.45e8 2.53e8 2.64e8 2.78e8 2.91e8 3.08e8 3.26e8 3.36e8 3.35e8 3.64e8 3.79e8 3.99e8 4.33e8 4.61e8 4.86e8 5.25e8 5.55e8 ## 4 II Cagayan… 1.58e8 1.64e8 1.66e8 1.71e8 1.86e8 1.83e8 2.01e8 2.14e8 2.19e8 2.24e8 2.33e8 2.48e8 2.65e8 2.89e8 3.13e8 3.26e8 3.42e8 3.68e8 ## 5 III Central… 7.07e8 7.49e8 7.92e8 8.26e8 8.52e8 8.86e8 9.27e8 9.82e8 1.03e9 1.04e9 1.14e9 1.23e9 1.34e9 1.42e9 1.53e9 1.62e9 1.75e9 1.93e9 ## 6 IVA CALABAR… 1.05e9 1.07e9 1.12e9 1.18e9 1.24e9 1.31e9 1.37e9 1.45e9 1.50e9 1.49e9 1.64e9 1.68e9 1.81e9 1.94e9 2.05e9 2.20e9 2.35e9 2.53e9 ## # ℹ 6 more variables: `2018` &lt;dbl&gt;, `2019` &lt;dbl&gt;, `2020` &lt;dbl&gt;, `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt; We need to convert the columns to have the same format first so that we can edit all of them later on when we transform to long format since different formats cannot be combined when modifying to long format. colnames(rgdp)&lt;-as.character(colnames(rgdp)) rgdp&lt;-rgdp %&gt;% select(-&quot;...1&quot;) Now, we can modify library(tidyverse) rgdpl&lt;-rgdp %&gt;% pivot_longer(cols = -region, names_to = &quot;Year&quot;, values_to = &quot;GDP&quot;) %&gt;% mutate(Year=as.numeric(Year), GDP=as.numeric(GDP)) head(rgdpl) ## # A tibble: 6 × 3 ## region Year GDP ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 National Capital Region 2000 2416391870. ## 2 National Capital Region 2001 2483504980. ## 3 National Capital Region 2002 2507171644. ## 4 National Capital Region 2003 2624052475. ## 5 National Capital Region 2004 2841837836. ## 6 National Capital Region 2005 2988546218. unique(rgdpl$region) ## [1] &quot;National Capital Region&quot; &quot;Cordillera Administrative Region&quot; &quot;Ilocos Region&quot; ## [4] &quot;Cagayan Valley&quot; &quot;Central Luzon&quot; &quot;CALABARZON&quot; ## [7] &quot;MIMAROPA Region&quot; &quot;Bicol Region&quot; &quot;Western Visayas&quot; ## [10] &quot;Central Visayas&quot; &quot;Eastern Visayas&quot; &quot;Zamboanga Peninsula&quot; ## [13] &quot;Northern Mindanao&quot; &quot;Davao Region&quot; &quot;SOCCSKSARGEN&quot; ## [16] &quot;Caraga&quot; &quot;BARMM&quot; Since we know that the names are different in the shapefile, we rename the regions so that they match through mapping. region_mapping &lt;- c( &quot;Ilocos Region&quot; = &quot;Region I (Ilocos Region)&quot;, &quot;Cagayan Valley&quot; = &quot;Region II (Cagayan Valley)&quot;, &quot;Central Luzon&quot; = &quot;Region III (Central Luzon)&quot;, &quot;CALABARZON&quot; = &quot;Region IV-A (CALABARZON)&quot;, &quot;Bicol Region&quot; = &quot;Region V (Bicol Region)&quot;, &quot;Western Visayas&quot; = &quot;Region VI (Western Visayas)&quot;, &quot;Central Visayas&quot; = &quot;Region VII (Central Visayas)&quot;, &quot;Eastern Visayas&quot; = &quot;Region VIII (Eastern Visayas)&quot;, &quot;Zamboanga Peninsula&quot; = &quot;Region IX (Zamboanga Peninsula)&quot;, &quot;Northern Mindanao&quot; = &quot;Region X (Northern Mindanao)&quot;, &quot;Davao Region&quot; = &quot;Region XI (Davao Region)&quot;, &quot;SOCCSKSARGEN&quot; = &quot;Region XII (SOCCSKSARGEN)&quot;, &quot;National Capital Region&quot; = &quot;National Capital Region (NCR)&quot;, &quot;Cordillera Administrative Region&quot; = &quot;Cordillera Administrative Region (CAR)&quot;, &quot;Caraga&quot; = &quot;Region XIII (Caraga)&quot;, &quot;BARMM&quot; = &quot;Bangsamoro Autonomous Region In Muslim Mindanao (BARMM)&quot;, &quot;MIMAROPA Region&quot; = &quot;MIMAROPA Region&quot; ) rgdpl$region &lt;- dplyr::recode(rgdpl$region, !!!region_mapping) setdiff(sp_df$region, rgdpl$region) # Should be (0) ## character(0) Now, we can merge. rgdp_map&lt;-sp_df %&gt;% left_join(rgdpl, by = &quot;region&quot;) setdiff(rgdpl$region, sp_df$region) ## character(0) #remove unnecessary columns and mutate GDP to billions rgdp_map &lt;- rgdp_map %&gt;% select(region, Year, GDP, geometry) %&gt;% mutate(GDP = GDP / 1e9) 9.7.0.1 Choropleth Map A Choropleth Map is a type of thematic map where regions are color-coded based on a statistical value (e.g., GDP, population, unemployment rate, etc.). It is commonly used in geographic data visualization to show spatial variations across different regions. For the static map, let us choose the latest year, 2023; rgdp2023&lt;-rgdp_map %&gt;% filter(Year==2023) library(scales) ## ## Attaching package: &#39;scales&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor # Modify the Choropleth Map ggplot(rgdp2023) + geom_sf(aes(fill = GDP), color = &quot;white&quot;) + # Fill regions based on GDP scale_fill_viridis_c( option = &quot;magma&quot;, name = &quot;GDP (2023)&quot;, labels = label_number(accuracy = 0.1, suffix = &quot;B&quot;, big.mark = &quot;,&quot;) # Fix rounding issue ) + labs(title = &quot;Regional GDP of the Philippines (2023)&quot;) + theme_minimal() #Saving the images #ggsave(&quot;rgdp2023.jpg&quot;, plot = last_plot(), width = 10, height = 8, dpi = 300) #or plot = nameofplot, width and height are in inches and for high quality image, dpi = 300 9.7.0.2 Bubble Map A Bubble Map is a type of thematic map that represents data values using circles (bubbles) placed over specific locations. The size of the bubble corresponds to the magnitude of the variable being visualized (e.g., GDP, population, sales, etc.). We use 2023 again. The first step that we need to do is calculate the centroids using st_centroid from the sf package because this calculates the geometric center of each polygon region in the shapefile. These will be used as our bubble locations and to ensure that there will be no overlapping with borders. phr_centroids&lt;-st_centroid(rgdp2023) ## Warning: st_centroid assumes attributes are constant over geometries print(phr_centroids) ## Simple feature collection with 17 features and 3 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 119.8902 ymin: 6.580654 xmax: 125.8263 ymax: 17.35385 ## Geodetic CRS: WGS 84 ## First 10 features: ## region Year GDP geometry ## 1 Region I (Ilocos Region) 2023 0.7014687 POINT (120.4827 16.90283) ## 2 Region II (Cagayan Valley) 2023 0.4470732 POINT (121.7316 17.20396) ## 3 Region III (Central Luzon) 2023 2.3184283 POINT (120.8223 15.3919) ## 4 Region IV-A (CALABARZON) 2023 3.0952557 POINT (121.568 14.16225) ## 5 Region V (Bicol Region) 2023 0.6103399 POINT (123.4734 13.27216) ## 6 Region VI (Western Visayas) 2023 1.0242699 POINT (122.652 10.84319) ## 7 Region VII (Central Visayas) 2023 1.3811721 POINT (123.6147 9.921139) ## 8 Region VIII (Eastern Visayas) 2023 0.5235611 POINT (124.9534 11.53574) ## 9 Region IX (Zamboanga Peninsula) 2023 0.4473210 POINT (122.8477 7.825902) ## 10 Region X (Northern Mindanao) 2023 0.9847503 POINT (124.6742 8.187355) We now create our Bubble Map ggplot()+ geom_sf(data=rgdp2023, fill = &quot;gray&quot;, color=&quot;white&quot;)+#base map geom_point(data = phr_centroids, aes(x = st_coordinates(geometry)[,1], y = st_coordinates(geometry)[,2], size = GDP, color = GDP), alpha = 0.7) + scale_size(range = c(2, 15), name = &quot;GDP (2023)&quot;) + # Adjust bubble size scale_color_viridis_c(option = &quot;magma&quot;, name = &quot;GDP (2023)&quot;, labels = label_number(accuracy = 0.1, suffix = &quot;B&quot;, big.mark = &quot;,&quot;)) + labs(title = &quot;Regional GDP of the Philippines (2023)&quot;, subtitle = &quot;Bubble Size Represents GDP&quot;, x=&quot;Coordinates&quot;, y=&quot;Coordinates&quot;)+ theme_minimal() As you can see, the base map is drawn using geom_sf() then the bubbles represent the GDP values. The bubble size and color represent GDP magnitude. You will notice that ggplot() is empty, this creates an empty ggplot canvas where the map layers will be added using the geom_sf. In the aes there’s x = st_coordinates(geometry)[,1] same for y. These extract the longitude and latitude of each centroid. The scale_size() range sets the bubble sizes between 2 and 15 units but you can edit this. Now, scale_viridis_c has more things, the name sets the legend title for GDP colors. the labels ensures decimal precision and adds suffix B, plus, adds comma separators since we do not want the legend to contain scientific notations. 9.8 Animated Map 9.8.0.1 Animated Philippine Regional GDP Choropleth Map We will now make an animated version of the Regional GDP Choropleth Map since we have data from 2000 to 2023. Let’s convert to billions like what we did for the 2023. It takes really long to render (it depends on the memory you have in your laptops) so, I will place the best strategy, that is creating static maps and combining them to form a video. Notice that when cleaning the environment, I chose to keep rgdp_map since we will still use this. rm(list = setdiff(ls(), &quot;rgdp_map&quot;)) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 3838195 205.0 6563742 350.6 6563742 350.6 ## Vcells 34648925 264.4 194747188 1485.9 243425312 1857.2 #for mp4 if (!require(av)) install.packages(&quot;av&quot;) ## Loading required package: av library(av) We need to create a directory within our working directory where the images will be saved. dir.create(&quot;ch_gdp_frames&quot;, showWarnings = FALSE) We now generate static maps; this requires us to create a function/loop. When we use the av, the default is a black setting so it’s better to have a white background set for the plot and the entire canvas. for(year in 2000:2023){ #filter data for the specific year data_year&lt;-rgdp_map %&gt;% filter(Year==year) #Generate the plot ip&lt;-ggplot(data_year) + geom_sf(aes(fill = GDP), color = &quot;white&quot;) + scale_fill_viridis_c( option = &quot;magma&quot;, name = &quot;GDP&quot;, labels = scales::label_number(accuracy = 0.1, suffix = &quot;B&quot;, big.mark = &quot;,&quot;) ) + labs( title = paste(&quot;Regional GDP of the Philippines&quot;), subtitle = paste(&quot;Year:&quot;, year), fill = &quot;GDP (Billion $)&quot; ) + theme_minimal() + theme( plot.title = element_text(size = 16, face = &quot;bold&quot;), plot.subtitle = element_text(size = 14), panel.background = element_rect(fill = &quot;white&quot;, color = NA), # Set white background plot.background = element_rect(fill = &quot;white&quot;, color = NA) # Set white background ) # Save the plot as an image ggsave(filename = paste0(&quot;ch_gdp_frames/gdp_&quot;, year, &quot;.png&quot;), plot = ip, width = 8, height = 6, dpi = 300) } You need to edit some parts, such as the 2000:2023 with whatever years you have; you need to filter data depending on how you called the time column. Then edit the fill and other things. We now combine our static maps into MP4. If you want the transition for each year to be seen clearly, the framerate is set at 1 to have 1 frame per second and the frame is repeated twice. the vfilter makes the video HD file_list &lt;- list.files(&quot;ch_gdp_frames&quot;, pattern = &quot;gdp_.*\\\\.png&quot;, full.names = TRUE) rep_files &lt;- rep(file_list, each = 2) # Repeat each frame twice av::av_encode_video( input = rep_files, output = &quot;ch_rgdp_time.mp4&quot;, framerate = 1, vfilter = &quot;scale=1280:720&quot; ) 9.9 Practical: Advanced Visualizations For the practical, you need to search and clean the dataset on your own. Please search in PSA OpenStat: Number of Registered Live Births by Sex and by Usual Residence of Mother (Region, Province and Highly Urbanized City), Philippines: January - December 2013-2022. Only gather regional data since the shapefile that is given for this practical is for Regions only. Please save each animation using anim_save Using PSA OpenStat (2013-2022) data, create an animated bar chart showing the total number of live births per year. Differentiate Male vs. Female births using fill Create an animated bar chart that compares the number of live births per region over time (2013-2022). Use transition_states(year, wrap = FALSE) to animate regional birth counts changing over time. Determine the region with the highest live births in each frame. Select 3-5 regions and visualize their live birth trends (2013-2022) using an animated time series plot. Using PSA OpenStat (2013-2022) data and a Philippines regional shapefile, create a static choropleth map of the recent number of live births per region. Color the regions based on birth count Using PSA OpenStat (2013-2022) data and a Philippines regional shapefile, create an animated choropleth map showing how the number of live births per region changes over time. Color the regions based on birth count How do birth trends differ across Philippine regions? Which regions have experienced the highest increase or decrease in live births from 2013 to 2022? How does using gganimate with sf enhance your ability to analyze spatial(and time) data trends? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
